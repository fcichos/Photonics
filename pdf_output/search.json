[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Photonics",
    "section": "",
    "text": "Photonics Logo\n\n\nPhotonics is a field of science that is manipulating the flow of light. It contains many facets of research involving light propgation from fundamentals involving light matter interaction to applications involving photonic computing with disordered media or single light quanta to adaptive superresolution microscopy. It is one of the fastest growing fields.\nIn this course we will introduce into the field of optics and photonics. We will start with simple but powerful descriptions of light propagation using ray optics to more advanced physics using electromagnetic waves. We will explore Fourier optics, anisotropic media and non-linear optics to lay the foundation to more complex topics in advanced lecture series.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Photonics</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html",
    "href": "lectures/lecture01/01-lecture01.html",
    "title": "2  Theories for light",
    "section": "",
    "text": "2.0.1 Ray Optics\nLight has been described through increasingly sophisticated theoretical frameworks throughout the history of physics. The simplest framework is Ray Optics or Geometrical Optics, which treats light as rays traveling along straight paths and applies geometrical principles to describe interactions with optical elements like lenses and mirrors. Moving beyond this approximation, Wave Optics introduces the wave nature of light, explaining phenomena such as interference and diffraction that ray optics cannot address. Electromagnetic Optics further refines our understanding by treating light as electromagnetic waves governed by Maxwell’s equations, providing a complete classical description of light-matter interactions. For intense light sources, Nonlinear Optics becomes essential, describing how materials respond nonlinearly to strong electromagnetic fields, giving rise to frequency conversion and other novel effects. Finally, at the most fundamental level, Quantum Optics treats light as consisting of photons—quantum mechanical particles exhibiting both wave and particle properties—essential for understanding phenomena like spontaneous emission, entanglement, and the quantum nature of light-matter interactions. This course will progressively build your understanding through these increasingly sophisticated frameworks.\nRay optics, or geometric optics, provides a powerful framework for understanding light propagation when the wavelength is much smaller than the dimensions of optical elements involved. In this approach, light travels along straight lines called rays in homogeneous media, with well-defined paths that can be mathematically traced. This description serves as the foundation for analyzing many optical systems, from simple mirrors to complex microscopes and telescopes.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#fermats-principle-for-spherical-surfaces",
    "href": "lectures/lecture01/01-lecture01.html#fermats-principle-for-spherical-surfaces",
    "title": "2  Theories for light",
    "section": "2.1 Fermat’s Principle for Spherical Surfaces",
    "text": "2.1 Fermat’s Principle for Spherical Surfaces\nThe power of Fermat’s principle becomes particularly evident when applied to spherical refracting surfaces. Consider a spherical boundary of radius \\(R\\) between two media with refractive indices \\(n_1\\) and \\(n_2\\). According to Fermat’s principle, light will follow the path that minimizes the total optical path length.\n\n\n\n\n\n\n\n\nFigure 2.12— Fermat’s principle applied to a spherical refracting surface\n\n\n\n\n\nWhen we apply Fermat’s principle to a spherical surface, we can derive the laws of refraction. Consider a spherical boundary between two media with refractive indices \\(n_1\\) and \\(n_2\\). We’ll place our coordinate system so that the spherical surface intersects the x-axis at x=0, with radius R and its center at position (R,0) to the right.\nFor a point P on the spherical surface at height y from the optical axis, the total optical path length from object point A at (-a,0) to image point B at (b,0) is:\n\\[L = n_1|AP| + n_2|PB|\\]\nwhere: \\[|AP| = \\sqrt{a^2 + y^2}\\] \\[|PB| = \\sqrt{b^2 + y^2}\\]\nAccording to Fermat’s principle, light follows the path where this length is stationary:\n\\[\\frac{dL}{dy} = n_1\\frac{d|AP|}{dy} + n_2\\frac{d|PB|}{dy} = 0\\]\nComputing these derivatives:\n\\[\\frac{d|AP|}{dy} = \\frac{y}{|AP|}\\] \\[\\frac{d|PB|}{dy} = \\frac{y}{|PB|}\\]\nSubstituting into our condition:\n\\[n_1\\frac{y}{|AP|} + n_2\\frac{y}{|PB|} = 0\\]\nThis equation is incorrect. The right-hand side should not be zero because we need to account for the geometry of the spherical surface. The correct form includes the effect of the surface normal:\n\\[n_1\\frac{y}{|AP|} + n_2\\frac{y}{|PB|} = \\frac{(n_2-n_1)y}{R}\\]\nThis correction comes from the fact that at point P, the normal to the spherical surface makes an angle α with the optical axis, where sin(α) ≈ y/R in the paraxial approximation.\nDividing by y (assuming y≠0):\n\\[\\frac{n_1}{|AP|} + \\frac{n_2}{|PB|} = \\frac{n_2-n_1}{R}\\]\nIn the paraxial approximation, we can use |AP| ≈ a and |PB| ≈ b, yielding:\n\\[\\frac{n_1}{a} + \\frac{n_2}{b} = \\frac{n_2-n_1}{R}\\]\nThis is the correct imaging equation for a spherical refracting surface.\nThe elegance of Fermat’s principle is preserved, as it still naturally produces the same result as our geometric derivation, once we properly account for the geometry of the refracting surface.\n\n\n\n\n\n\nDeriving the Thin Lens Equation from Fermat’s Principle\n\n\n\n\n\nTo derive the thin lens equation, we apply Fermat’s principle to the two spherical surfaces that make up a lens. Consider a lens with refractive index \\(n_2\\) in a medium of index \\(n_1\\), with surface radii \\(R_1\\) and \\(R_2\\).\nThe total optical path for a ray passing through the lens at height \\(y\\) from the optical axis is: - Path from object to first surface: \\(n_1 s_1\\) - Path through the lens: \\(n_2 s_2\\) - Path from second surface to image: \\(n_1 s_3\\)\nFor a thin lens, the optical path length simplifies to:\n\\[L(y) = n_1 \\sqrt{a^2 + y^2} + n_2 d(y) + n_1 \\sqrt{b^2 + y^2}\\]\nWhere \\(d(y)\\) is the thickness of the lens at height \\(y\\), which can be approximated as:\n\\[d(y) \\approx d_0 + \\frac{y^2}{2}\\left(\\frac{1}{R_1}-\\frac{1}{R_2}\\right)\\]\nApplying Fermat’s principle (\\(\\frac{dL}{dy} = 0\\)) and using the paraxial approximation:\n\\[\\frac{n_1 y}{\\sqrt{a^2 + y^2}} + n_2 y \\left(\\frac{1}{R_1}-\\frac{1}{R_2}\\right) + \\frac{n_1 y}{\\sqrt{b^2 + y^2}} = 0\\]\nIn the paraxial limit (\\(y \\ll a, y \\ll b\\)), this becomes:\n\\[\\frac{n_1 y}{a} + n_2 y \\left(\\frac{1}{R_1}-\\frac{1}{R_2}\\right) + \\frac{n_1 y}{b} = 0\\]\nDividing by \\(y\\) and rearranging:\n\\[\\frac{1}{a} + \\frac{1}{b} = \\frac{n_2-n_1}{n_1}\\left(\\frac{1}{R_1}-\\frac{1}{R_2}\\right) = \\frac{1}{f}\\]\nThis is the thin lens equation with the focal length given by the lensmaker’s equation:\n\\[f = \\frac{n_1}{n_2-n_1}\\left(\\frac{R_1 R_2}{R_2-R_1}\\right)\\]\nThus, both the imaging equation and the lensmaker equation emerge naturally from Fermat’s principle applied to the geometry of a thin lens, showing that light follows paths of equal optical length from object to image when passing through any part of the lens.\nFrom a wave perspective, what makes a lens focus light to a point is that all paths from object to image through any part of the lens have equal optical path lengths (to first order in the paraxial approximation), ensuring constructive interference at the image point.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html",
    "href": "lectures/lecture02/01-lecture02.html",
    "title": "3  Theories for light",
    "section": "",
    "text": "3.0.1 Refraction at Spherical Surfaces\nWhen light encounters a spherical boundary between two media, we can analyze its path using Snell’s law and geometric considerations as shown below:\n\n\n\n\n\n\nFigure 3.1— Refraction at a curved surface.\n\n\n\nTo determine how an image forms, we need to find where rays originating from a point at distance \\(a\\) from the surface will converge after refraction. Using Snell’s law for a ray hitting the surface at angle \\(\\alpha+\\theta_1\\):\n\\[n_{1}\\sin(\\alpha+\\theta_1)=n_{2}\\sin(\\alpha-\\theta_2)\\]\nWhere: \\[\\sin(\\alpha)=\\frac{y}{R}, \\quad \\tan(\\theta_1)=\\frac{y}{a}, \\quad \\tan(\\theta_2)=\\frac{y}{b}\\]\nFor practical optical systems, we employ the paraxial approximation, where all angles are assumed small enough that:\n\\[\\sin(\\theta) \\approx \\theta+ O(\\theta^{3}), \\quad \\tan(\\theta) \\approx \\theta + O(\\theta^{3}),\\quad \\cos(\\theta)\\approx 1 + O(\\theta^{2})\\]\nThis simplifies Snell’s law to:\n\\[n_1(\\alpha+\\theta_1)=n_2(\\alpha-\\theta_2)\\]\nAfter appropriate transformations (detailed in the online lecture), we obtain:\n\\[\\theta_2=\\frac{n_2-n_1}{n_2 R}y -\\frac{n_1}{n_2}\\theta_1\\]\nand\n\\[y=y_1=y_2\\]\nThis linear relationship between input (\\(y\\), \\(\\theta_1\\)) and output (\\(y\\),\\(\\theta_2\\)) parameters is a hallmark of paraxial optics and a result of the linearization of Snells law.\n\n\n3.0.2 Matrix Optics\nThe linear relation between input and output parameters allows us to express optical elements as linear transformations (matrices). This approach forms the foundation of matrix optics. For a lens, the matrix representation is:\n\\[\\begin{pmatrix} y_2 \\\\ \\theta_2 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{1}{f} & 1 \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ \\theta_1 \\end{pmatrix}\\]\nThis 2×2 matrix is called the ABCD matrix of the lens. Thanks to the linearization of Snell’s law, we can generalize this to any optical element:\n\\[\\begin{pmatrix} y_2 \\\\\n\\theta_2 \\end{pmatrix} = \\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ \\theta_1 \\end{pmatrix}\\]\nEach element in the ABCD matrix has a specific physical meaning:\n\n\n\n\n\n\n\nMatrix Element\nPhysical Meaning\n\n\n\n\nA\nMagnification - relates output position to input position\n\n\nB\nPosition-to-angle conversion - relates output position to input angle\n\n\nC\nFocusing power - relates output angle to input position\n\n\nD\nAngular magnification - relates output angle to input angle\n\n\n\nEvery optical element can be characterized by these parameters. For example, a lens has C = -1/f (focusing power), while free space has B = d (position-dependent angle change). An important property is that the determinant of the matrix equals the ratio of refractive indices: det(M) = n₁/n₂, which equals 1 in a single medium.\nHere are the ABCD matrices for common optical elements:\n\\[\n\\mathbf{M}=\\begin{bmatrix}\nA & B\\\\\nC & D\n\\end{bmatrix} =\\left[\\begin{array}{ll}\n1 & d \\\\\n0 & 1\n\\end{array}\\right] \\tag{Free space}\n\\]\n\\[\n\\mathbf{M}=\\left[\\begin{array}{cc}\n1 & 0 \\\\\n0 & \\frac{n_1}{n_2}\n\\end{array}\\right] \\tag{Planar interface}\n\\]\n\\[\n\\mathbf{M}=\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{\\left(n_2-n_1\\right)}{n_2 R} & \\frac{n_1}{n_2}\n\\end{array}\\right] \\tag{Spherical Boundary}\n\\]\n\\[\n\\mathbf{M}=\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f} & 1\n\\end{array}\\right] \\tag{Thin Lens}\n\\]\nFor a system containing multiple optical elements, we simply multiply their matrices in the order that light passes through them:\n\\[\n\\mathrm{M}=\\mathbf{M}_N \\cdots \\mathbf{M}_2 \\mathbf{M}_1\n\\]\nA ray entering the first optical element at a height \\(y_1\\) at an angle \\(\\theta_1\\) is transformed according to the matrix \\(\\mathbf{M}\\) by the whole system. This elegant approach provides a powerful tool for analyzing complex optical systems efficiently.\n\n\n\n\n\n\nExample: Optical Cloaking with Lens Systems\n\n\n\n\n\nOptical cloaking refers to making objects “invisible” by guiding light rays around them such that to an observer, it appears as if the rays traveled through free space without encountering any object. Using matrix optics, we can design such a system.\n\n\n\n\n\n\nFigure 3.2— Example of a practical paraxial cloak. (a)–(c) A hand is cloaked for varying directions, while the background image is transmitted properly.(d) On-axis view of the ray optics cloaking device. (e) Setup using practical, easy to obtain optics, for demonstrating paraxial cloaking principles. (Photos by J. Adam Fenster, videos by Matthew Mann / University of Rochester) Source\n\n\n\nFor perfect optical cloaking, the ABCD matrix of our system must be equivalent to that of free space:\n\\[\n\\mathbf{M}_{cloaking} = \\left[\\begin{array}{cc}\n1 & d \\\\\n0 & 1\n\\end{array}\\right]\n\\]\nWhere \\(d\\) is the total effective optical path length. Let’s explore why we need exactly 4 lenses to achieve this.\n\n3.0.2.1 Analysis of Different Lens Configurations\n1. Single Lens Configuration\nFor a single lens with focal length \\(f\\), the ABCD matrix is:\n\\[\n\\mathbf{M}_{single} = \\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f} & 1\n\\end{array}\\right]\n\\]\nThis clearly cannot match the free space matrix due to the non-zero \\(C\\) element.\n2. Two-Lens Configuration\nFor two lenses with focal lengths \\(f_1\\) and \\(f_2\\) separated by distance \\(d_{12}\\):\n\\[\n\\mathbf{M}_{two} = \\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f_2} & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & d_{12} \\\\\n0 & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f_1} & 1\n\\end{array}\\right]\n\\]\nWhen \\(d_{12} = f_1 + f_2\\) (telescopic arrangement), this simplifies to:\n\\[\n\\mathbf{M}_{two} = \\left[\\begin{array}{cc}\n-\\frac{f_1}{f_2} & 0 \\\\\n0 & -\\frac{f_2}{f_1}\n\\end{array}\\right]\n\\]\nSince both magnification (\\(A\\)) and angular magnification (\\(D\\)) cannot simultaneously equal 1 while maintaining \\(\\det(\\mathbf{M}) = 1\\), two lenses are insufficient.\n3. Three-Lens Configuration\nWith three lenses, we have more parameters but still need to determine if we can satisfy all constraints simultaneously. For a three-lens system with focal lengths \\(f_1\\), \\(f_2\\), and \\(f_3\\), separated by distances \\(d_{12}\\) and \\(d_{23}\\), the system matrix would be:\n\\[\n\\mathbf{M}_{three} =\n\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f_3} & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & d_{23} \\\\\n0 & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f_2} & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & d_{12} \\\\\n0 & 1\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\n1 & 0 \\\\\n-\\frac{1}{f_1} & 1\n\\end{array}\\right]\n\\]\nWhen multiplied out, the focusing power (C element) of the system is:\n\\[C = -\\frac{1}{f_3} - \\frac{1}{f_2} - \\frac{1}{f_1} + \\frac{d_{12}}{f_1f_2} + \\frac{d_{23}}{f_2f_3} + \\frac{d_{12}d_{23}}{f_1f_2f_3}\\]\nThe magnification (A element) of the system is:\n\\[A = 1 - \\frac{d_{12}}{f_1} - \\frac{d_{23}}{f_2} + \\frac{d_{12}d_{23}}{f_1f_2}\\]\nFor perfect cloaking, we need both C = 0 and A = 1. From A = 1, we can derive:\n\\[\\frac{d_{12}}{f_1} + \\frac{d_{23}}{f_2} - \\frac{d_{12}d_{23}}{f_1f_2} = 0\\]\nSolving for \\(d_{23}\\), we get:\n\\[d_{23} = \\frac{d_{12}/f_1}{1/f_2 - d_{12}/(f_1f_2)}\\]\nSubstituting this into the condition for C = 0, we obtain a complex expression that places constraints on the possible values of \\(f_1\\), \\(f_2\\), and \\(f_3\\). For typical lens configurations, this results in values that are difficult to realize physically, as it often requires either negative separations or negative focal lengths.\nWhile the three-lens system provides more parameters to work with than the two-lens system, the mathematical constraints of simultaneously achieving zero focusing power (C = 0) and unit magnification (A = 1) still make perfect cloaking challenging with conventional optical elements.\n4. Four-Lens Configuration: The Solution\nWe can arrange four lenses in two pairs:\n\nFirst pair (lenses 1 and 2): A beam compressor\nSecond pair (lenses 3 and 4): A beam expander\n\nFor the beam compressor, with lenses at their combined focal length apart:\n\\[\n\\mathbf{M}_{comp} = \\left[\\begin{array}{cc}\n-\\frac{f_1}{f_2} & 0 \\\\\n0 & -\\frac{f_2}{f_1}\n\\end{array}\\right]\n\\]\nSimilarly, for the beam expander:\n\\[\n\\mathbf{M}_{exp} = \\left[\\begin{array}{cc}\n-\\frac{f_3}{f_4} & 0 \\\\\n0 & -\\frac{f_4}{f_3}\n\\end{array}\\right]\n\\]\nThe combined system matrix is:\n\\[\n\\mathbf{M}_{total} = \\mathbf{M}_{exp} \\times \\mathbf{M}_{comp} = \\left[\\begin{array}{cc}\n\\frac{f_1}{f_2} \\times \\frac{f_3}{f_4} & 0 \\\\\n0 & \\frac{f_2}{f_1} \\times \\frac{f_4}{f_3}\n\\end{array}\\right]\n\\]\nFor perfect cloaking, we need: - \\(\\frac{f_1}{f_2} \\times \\frac{f_3}{f_4} = 1\\) - \\(\\frac{f_2}{f_1} \\times \\frac{f_4}{f_3} = 1\\)\nThis is satisfied when \\(f_1 = f_4\\) and \\(f_2 = f_3\\).\nWith the lenses properly spaced and an additional free space distance \\(d_0\\) between the two pairs, the complete system matrix becomes:\n\\[\n\\mathbf{M}_{cloaking} = \\left[\\begin{array}{cc}\n1 & d_0 \\\\\n0 & 1\n\\end{array}\\right]\n\\]\nWhich perfectly mimics free space propagation, creating the optical cloaking effect.\n\n\nBeginnerHint [in figure.py]: Infinite field of view: cannot use limitObjectToFieldOfView=True. The object height is instead set to the default value of 10.0.\nBeginnerHint [in imagingpath.py]: Field of view is infinite. You can pass useObject=True to use the finite objectHeight.\nBeginnerHint [in figure.py]: No aperture stop in the system: cannot use onlyPrincipalAndAxialRays=True since they are not defined. Showing the default ObjectRays instead. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.0.3 Multifocal Imaging\nWe would like to explore the concept of multifocal imaging to obtain 3D resolution from a single image. In a microscope, an objective lens together with a tube lens is used to focus light from a sample onto a detector. Either the tube lens is no modified to shift the focal plane of the objective lens or one uses multiple tube lenses with different focal lengths with a single objective lens.\n\n\n\n\n\n\nFigure 3.3— The multifocal adapter. (a) Composition of the multifocal imaging setup. The multifocal adapter (MFA) is inserted into the light path between a standard dark-field microscope and a camera. (b) Composition of the multifocal adapter. Incoming light from the microscope is infinity projected by the lens f1 and split by three consecutive beam-splitters (b1 = 25/75; b2 = 33/67; b3 = 50/50). Five mirrors (m) guide the light into four separate optical paths. The lens f5 projects the four images onto the camera chip. The inter-plane distance is set by lenses of different focal length (f1 - f4). (c, d) Experimentally acquired (c) and simulated (d) (see Methods) multifocal dark-field images (planes 1 - 4, 20x objective) of a calibration grid at the four focal positions (indicated on the left side), where one of the four focal planes maps the grid sharply. Scale bar represents 20 µm. Experiment was performed six times with similar results. Source\n\n\n\nIn the simplest configuration of an objective lens and a tube lens, the light first travels from the object to the objective lens in free space for a distance \\(s\\), which is represented by\n\n\n\\[\nM_1=\\left[\\begin{matrix}1 & s\\\\0 & 1\\end{matrix}\\right]\n\\]\n\n\nThen it is passing the objective lens with\n\n\n\\[\nM_2=\\left[\\begin{matrix}1 & 0\\\\- \\frac{1}{f_{1}} & 1\\end{matrix}\\right]\n\\]\n\n\ntraveling further through free space with distance \\(d\\)\n\n\n\\[\nM_3=\\left[\\begin{matrix}1 & d\\\\0 & 1\\end{matrix}\\right]\n\\]\n\n\nand then hitting the tube lens with\n\n\n\\[\nM_4=\\left[\\begin{matrix}1 & 0\\\\- \\frac{1}{\\Delta_{ft} + f_{t}} & 1\\end{matrix}\\right]\n\\]\n\n\nwhere \\(\\Delta_ft\\) is a parameter modifying the original tube lens focal distance \\(f_t\\). Finally, the light will propagate to the detector at distance \\(f_t\\) from the tube lens\n\n\n\\[\nM_s=\\left[\\begin{matrix}1 & f_{t}\\\\0 & 1\\end{matrix}\\right]\n\\]\n\n\ngicing for the whole system:\n\\[\nM_t=M_4 M_3 M_2 M_1\n\\]\nThe final matrix has again 4 parameters \\(A,B,C\\) and \\(D\\). For sharp imaging the parameter \\(B\\) of the system must be equal to zero, as the outgoing light should be independent of the incoming angle. This is achieved\n\n\n\\[\\delta s=\\frac{f_{1} \\left(\\Delta_{ft} d + \\Delta_{ft} f_{t} + f_{t}^{2}\\right)}{\\Delta_{ft} d - \\Delta_{ft} f_{1} + \\Delta_{ft} f_{t} + f_{t}^{2}}-s_0\n\\]\n\n\n\n\n\n\n\n\n\n\nFigure 3.4— Plot of the solution with specific parameter values\n\n\n\n\n\n\n\n\n\n\n\nThe B Parameter\n\n\n\n\n\nThe B parameter is the most direct indicator of a sharp image in matrix optics. For an optical system with ABCD matrix: \\[\n\\begin{pmatrix} y_2 \\\\ \\theta_2 \\end{pmatrix} =\n\\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix}\n\\begin{pmatrix} y_1 \\\\ \\theta_1 \\end{pmatrix}\n\\]\nThe output position is given by: \\[y_2 = Ay_1 + B\\theta_1\\]\nFor an image to be sharp, all rays originating from the same object point must converge to a single image point, regardless of their initial angles. This means that for a given \\(y_1\\) (object position), the final position \\(y_2\\) must be independent of the initial angle \\(\\theta_1\\).\nThis condition is satisfied when B = 0.\nWhen B = 0: - The final position depends only on the initial position (\\(y_2 = Ay_1\\)) - All rays from a point source converge to a single point in the image plane - The imaging is “stigmatic” (point-to-point mapping)\nIn our lens example, the system matrix was: \\[\n\\mathbf{M}_{system} =\n\\left[\\begin{array}{cc}\n1-\\frac{d}{f} & d \\\\\n-\\frac{1}{f} & 1\n\\end{array}\\right]\n\\]\nFor parallel input rays (different \\(y_1\\) but all \\(\\theta_1 = 0\\)), we needed A = 0 to make them all converge to a single point, which happened when d = f.\nBut for general imaging of points (not just parallel rays), the B = 0 condition is what determines whether the image is sharp. This is why, in optical design, finding conjugate planes (where B = 0) is essential for sharp imaging.",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html",
    "href": "lectures/lecture02/02-lecture02.html",
    "title": "4  Theories for light",
    "section": "",
    "text": "4.0.1 Wave Optics\nWave optics extends our understanding beyond the limitations of geometric optics by treating light as a wave phenomenon. This approach explains effects that cannot be accounted for by ray tracing alone, such as:\nLight is part of the electromagnetic spectrum, which spans an enormous range of frequencies. The visible region, extending approximately from 400 nm (violet) to 700 nm (red), represents only a small fraction of this spectrum. This wave description is essential for understanding many optical phenomena that geometric optics cannot explain, particularly when dealing with structures comparable in size to the wavelength of light.\nIn the following, we would like to introduce wave by discarding the fact, that light is related to electric and magnetic fields. This is useful as the vectorial nature of the electric and magnetic field further complicates the calculations, but we do not need those yet. Accordingly we also do not understand how light really interacts with matter and we therefore have to introduce some postulates as well.",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#postulates-of-wave-optics",
    "href": "lectures/lecture02/02-lecture02.html#postulates-of-wave-optics",
    "title": "4  Theories for light",
    "section": "4.1 Postulates of Wave Optics",
    "text": "4.1 Postulates of Wave Optics\n\n\n\n\n\n\nWave\n\n\n\nA wave corresponds to a physical quantity which oscillates in space and time. Its energy current density is related to the square magnitude of the amplitude. A wave satisfies the wave equation.\n\n\n\n4.1.1 Wave equation\n\\[\n\\nabla^2 u - \\frac{1}{c^2}\\frac{\\partial^2 u}{\\partial t^2}=0\n\\]\nwhere the Laplace operator \\(\\nabla^2\\) is defined as:\n\\[\n\\nabla^2 =\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2}+\\frac{\\partial^2}{\\partial z^2}\n\\]\nThe wave equation is a linear differential equation, which implies that the superposition principle holds. Specifically, if \\(u_1(\\mathbf{r},t)\\) and \\(u_2(\\mathbf{r},t)\\) are solutions of the wave equation, then any linear combination:\n\\[\nu(\\mathbf{r},t)=a_1u_1(\\mathbf{r},t)+a_2u_2(\\mathbf{r},t)\n\\]\nis also a solution, where \\(a_1\\) and \\(a_2\\) are arbitrary constants.\n\n\n4.1.2 Monochromatic Wave\nA monochromatic wave consists of a single frequency \\(\\omega\\). By definition, such a wave must be infinite in time and free from phase disturbances (such as sudden jumps). The mathematical expression for a monochromatic wave is:\n\\[u(\\mathbf{r},t)=a(\\mathbf{r})\\cos(\\omega t + \\phi(\\mathbf{r}))\\]\nwhere:\n\n\\(a(\\mathbf{r})\\) represents the amplitude\n\\(\\phi(\\mathbf{r})\\) represents the spatial phase\n\\(\\omega\\) represents the angular frequency\n\n\n\n\n\n\n\nFigure 4.2— Representation of a wavefunction over time (constant position) denoting the phase \\(\\phi\\) and the period \\(T=1/\\nu\\)\n\n\n\n\n4.1.2.1 Complex Amplitude\nThe wave can be represented in complex form as:\n\\[\nU(\\mathbf{r},t)=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}e^{i\\omega t}\n\\]\nThis is known as the complex wavefunction.\n\n\n\n\n\n\nFigure 4.3— Phasor diagram of the complex amplitude \\(U(\\mathbf{r})\\) (left) and \\(U(t)\\) (right)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA phasor displays the complex amplitude with magnitude and phase as a vector in the complex plane.\n\n\nThe relationship between the complex and real wavefunctions is:\n\\[\nu(\\mathbf{r},t)=\\text{Re}\\{U(\\mathbf{r},t)\\}=\\frac{1}{2}[U(\\mathbf{r},t)+U^*(\\mathbf{r},t)]\n\\]\nThe complex wavefunction satisfies the same wave equation:\n\\[\n\\nabla^2 U - \\frac{1}{c^2}\\frac{\\partial^2 U}{\\partial t^2}=0\n\\]\nWe can separate the complex wavefunction into spatial and temporal components:\n\\[\nU(\\mathbf{r},t)=U(\\mathbf{r})e^{i\\omega t}\n\\]\nwhere\n\\[\nU(\\mathbf{r})=a(\\mathbf{r})e^{i\\phi(\\mathbf{r})}\n\\]\nHere, \\(\\phi\\) represents the spatial phase of the wavefunction. Substituting this into the wave equation and noting that the time derivatives bring down factors of \\(i\\omega\\):\n\\[\\nabla^2 [U(\\mathbf{r})e^{i\\omega t}] - \\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}[U(\\mathbf{r})e^{i\\omega t}] = 0\\] \\[\\nabla^2 U(\\mathbf{r})e^{i\\omega t} + \\frac{\\omega^2}{c^2}U(\\mathbf{r})e^{i\\omega t} = 0\\]\nThe time dependence \\(e^{i\\omega t}\\) factors out, leaving us with the Helmholtz equation:\n\\[\\nabla^2 U(\\mathbf{r}) + k^2U(\\mathbf{r}) = 0\\]\nwhere \\(k = \\omega/c\\) is the wave number. This equation describes the spatial behavior of monochromatic waves.\n\n\n4.1.2.2 Intensity of Waves\nThe intensity of a wave at position \\(\\mathbf{r}\\) and time \\(t\\) is defined as:\n\\[\nI(\\mathbf{r},t)=2\\langle u^2(\\mathbf{r},t)\\rangle\n\\]\nwhere \\(I\\) is measured in units of \\(\\left[\\frac{W}{m^2}\\right]\\). The angle brackets \\(\\langle \\ldots \\rangle\\) represent a time average over one oscillation cycle of \\(u\\). For visible light, this averaging occurs over an extremely brief period - for example, light with a wavelength of 600 nm has a cycle duration of just 2 femtoseconds.\nThe optical power \\(P\\) of a wave can be calculated by integrating the intensity over a surface area \\(A\\):\n\\[\nP=\\int_A I(\\mathbf{r},t) \\, dA\n\\]\nInserting the seperation of the complex wavefunction into spatial and temporal components leads to the following expression for the intensity:\n\\[\nI(\\mathbf{r})=|U(\\mathbf{r})|^2\n\\]\nThus the physical quantity forming the spatial and temporal oscillation of the wavefunction is also providing the intensity of the wave when its magnitude is squared. This is a fundamental property of wavefunctions and for example not the case when temperature oscillates in space and time in a medium.\n\n\n4.1.2.3 Wavefronts\nWavefronts are surfaces in space where the phase is constant:\n\\[\n\\phi(\\mathbf{r})=\\text{const}\n\\]\nTypically, this constant is chosen to represent points of maximum spatial amplitude, such that:\n\\[\n\\phi(\\mathbf{r})=2\\pi q\n\\]\nwhere \\(q\\) is an integer.\nThe direction normal to these wavefronts can be described by the gradient vector:\n\\[\n\\mathbf{n}=\\nabla\\phi=\\left(\\frac{\\partial \\phi}{\\partial x},\\frac{\\partial \\phi}{\\partial y},\\frac{\\partial \\phi}{\\partial z}\\right)\n\\]\nThis vector \\(\\mathbf{n}\\) is always perpendicular to the wavefront surface and points in the direction of wave propagation. The evolution of these wavefronts in time provides important information about the wave’s propagation characteristics.",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#plane-waves",
    "href": "lectures/lecture02/02-lecture02.html#plane-waves",
    "title": "4  Theories for light",
    "section": "4.2 Plane Waves",
    "text": "4.2 Plane Waves\nA plane wave represents a fundamental solution of the homogeneous wave equation. In its complex form, it is expressed as:\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwhere:\n\nThe first exponential term contains the spatial phase\nThe second exponential term contains the temporal phase\n\\(A\\) is the (potentially complex) amplitude of the plane wave\n\nThe wavefront of a plane wave is defined by:\n\\[\\mathbf{k}\\cdot \\mathbf{r}=2\\pi q + \\text{arg}(A)\\]\nwhere \\(1\\) is an integer. It just means that the projection of the position vector \\(\\mathbf{r}\\) onto the wavevector \\(\\mathbf{k}\\) is a multiple of \\(2\\pi\\). This equation describes a plane perpendicular to the wavevector \\(\\mathbf{k}\\). Adjacent wavefronts are separated by the wavelength \\(\\lambda=2\\pi/k\\), where \\(k\\) represents the spatial frequency of the wave oscillation.\nThe spatial component of the plane wave is given by:\n\\[\\begin{equation}\nU(\\mathbf{r})=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}\n\\end{equation}\\]\nIn vacuum, the wavevector \\(\\mathbf{k}=\\mathbf{k}_0\\) is real-valued and can be written as:\n\\[\\begin{equation}\n\\mathbf{k}_0=\n\\begin{pmatrix}\nk_{0x} \\\\\nk_{0y}\\\\\nk_{0z}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\n\n\n\n\n\n\n\nFigure 4.4— Plane wave propagating along the z-direction",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#dispersion-relation",
    "href": "lectures/lecture02/02-lecture02.html#dispersion-relation",
    "title": "4  Theories for light",
    "section": "4.3 Dispersion Relation",
    "text": "4.3 Dispersion Relation\nUsing the plane wave solution\n\\[\\begin{equation}\nU(\\mathbf{r},t)=Ae^{-i\\mathbf{k}\\cdot \\mathbf{r}}e^{i\\omega t}\n\\end{equation}\\]\nwe can write down the sum of the spatial and temporal phase as\n\\[\n\\phi(r,t)=\\omega t-\\mathbf{k}\\cdot \\mathbf{r}\n\\]\nIf we select a point on the wavefront \\(\\mathbf{r}_{m}\\), and follow that over time, the phase \\(\\phi(t)=\\text{const}\\). Taking the time derivative results in\n\\[\n\\mathbf{k}\\cdot \\frac{d\\mathbf{r}_{m}}{dt}=\\omega\n\\]\nIf we choose the direction of the wavevector for measuring the propagation speed, i.e. \\(\\mathbf{r}_{m}=r_{m}\\mathbf{e}_k\\) then we find for the propagation speed\n\\[\n\\frac{dr_{m}}{dt}=\\frac{\\omega}{k}\n\\]\nor in vacuum\n\\[\\begin{equation}\nc_0=\\frac{\\omega}{k_0}\n\\end{equation}\\]\nThis fundamental relationship connects:\n\nThe momentum (\\(k\\)),\nThe energy (\\(\\omega\\))\n\nand is called a dispersion relation despite the fact, that we do not really understand why those quantities are related to energy and momentum.\n\n\n\n\n\n\nNote\n\n\n\nLight in free space exhibits a linear dispersion relation, i.e. the frequency of light changes linearly with the wavevector magnitude.\n\n\nNote that if we choose a different propagation direction \\(\\mathbf{e}\\) than the one along the wavevector \\(\\mathbf{e}_k\\), we can write the phase velocity as\n\\[\n\\mathbf{k}\\cdot\\mathbf{e} \\frac{dr}{dt}=k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e}) \\frac{dr}{dt}=\\omega\n\\]\nor\n\\[\n\\frac{dr}{dt}=\\frac{\\omega}{k\\cos(\\measuredangle\\mathbf{k},\\mathbf{e})}\n\\]\nwhich means that if you observe the wavepropagation not in the direction of the wavevector, the phase velocity is actually bigger than the speed of light and even tends to infinity if the angle between the wavevector and the observation direction tends to 90°.",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#propagation-in-a-medium",
    "href": "lectures/lecture02/02-lecture02.html#propagation-in-a-medium",
    "title": "4  Theories for light",
    "section": "4.4 Propagation in a Medium",
    "text": "4.4 Propagation in a Medium\nWhen a wave propagates through a medium:\n\nThe frequency \\(\\omega\\) remains constant (determined by the source)\nThe wave speed changes according to: \\[\nc=\\frac{c_0}{n}\n\\] where \\(n\\) is the refractive index of the medium\n\nThis leads to changes in:\n\nthe wavelength, which becomes shorter in the medium \\[\n\\lambda=\\frac{\\lambda_0}{n}\n\\]\nthe length of the wavevector, which increases in the medium \\[\nk=nk_0\n\\]",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#snells-law",
    "href": "lectures/lecture02/02-lecture02.html#snells-law",
    "title": "4  Theories for light",
    "section": "4.5 Snells Law",
    "text": "4.5 Snells Law\nThe change in the length of the wavevector has some simple consequence for Snells law. We can write Snells law as\n\\[\nn_1k_0\\sin(\\theta_1)=n_2k_0\\sin(\\theta_2)\n\\]\nwhere \\(k_0\\) is the wavevector length in vacuum. As the \\(n_1k_0\\) is the magnitude of the wavevector in medium 1, and \\(n_2k_0\\) is the magnitude of the wavevector in medium 2, we can rewrite Snells law as\n\\[\nk_1\\sin(\\theta_1)=k_2\\sin(\\theta_2)\n\\]\nwhich means that the component of the wavevector parallel to the interface is conserved. If the wavevector has constant length then the wavevector incident at different angles is between a point on a circle and the origin in the diagram below. The circle corresponds to an isofrequency surface.\n\n\n\n\n\n\n\nSnells law construction using the conservation of the wavevector component parallel to the interface. The vertical dashed lines indicate the parallal component of the wavevector in the two media.\n\n\n\n\n\n\n\n\nElectron microscopy image of a 2D photonic crystal\n\n\n\n\n\n\n\nIsofrequency surfaces of a photonic crystal\n\n\n\n\n\nIsofrequency surfaces can have non-spherical shape. In anisotropic media, they can be ellipsoids. In photonic crystals, i.e. crystals with a periodic structure on the scale of the wavelength, they can have a more complex shape.",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html#spherical-waves",
    "href": "lectures/lecture02/02-lecture02.html#spherical-waves",
    "title": "4  Theories for light",
    "section": "4.6 Spherical Waves",
    "text": "4.6 Spherical Waves\nA spherical wave, like a plane wave, consists of spatial and temporal components, but with wavefronts forming spherical surfaces. For spherical waves, \\(|\\mathbf{k}||\\mathbf{r}|=kr=\\text{const}\\). Given a source at position \\(\\mathbf{r}_0\\), the spherical wave can be expressed as:\n\\[\\begin{equation}\nU=\\frac{A}{|\\mathbf{r}-\\mathbf{r}_0|}e^{-ik|\\mathbf{r}-\\mathbf{r}_0|} e^{i\\omega t}\n\\end{equation}\\]\n\n\n\n\n\n\nImportant\n\n\n\nThe \\(1/|\\mathbf{r}-\\mathbf{r}_0|\\) factor in the amplitude is necessary for energy conservation - ensuring that the total energy flux through any spherical surface centered on the source remains constant.\n\n\n\n\n\n\n\n\n\n\nFigure 4.5— Spherical wave propagation. The wave is emitted from the origin and propagates in the positive z-direction. The wavefronts are spherical surfaces. The wave is visualized in the xz-plane.\n\n\n\n\n\nNote: The direction of wave propagation can be reversed by changing the sign of the wavenumber \\(k\\).",
    "crumbs": [
      " Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html",
    "href": "lectures/lecture03/01-lecture03.html",
    "title": "5  Interference in space and time",
    "section": "",
    "text": "Interference is a fundamental physical phenomenon that demonstrates the superposition principle for linear systems. This principle, which states that the net response to multiple stimuli is the sum of the individual responses, is central to our understanding of wave physics. Interference appears across many domains of physics: in optics where it enables high-precision measurements and holography, in quantum mechanics where it reveals the wave nature of matter, and in acoustics where it forms the basis for noise cancellation technology. The ability of waves to interfere constructively (amplifying each other) or destructively (canceling each other) has profound practical applications, from the anti-reflective coatings on optical elements to the operational principles of interferometric gravitational wave detectors like LIGO. Understanding interference is therefore not just of theoretical interest but crucial for modern technology and experimental physics.\nWhen two wave solutions \\(U_1(\\mathbf{r})\\) and \\(U_2(\\mathbf{r})\\) combine, their superposition gives:\n\\[\nU(\\mathbf{r})=U_1(\\mathbf{r})+U_2(\\mathbf{r})\n\\]\nThe resulting intensity is:\n\\[\\begin{eqnarray}\nI &= &|U|^2\\\\\n&= &|U_1+U_2|^2\\\\\n&= &|U_1|^2+|U_2|^2+U^{*}_1 U_2 + U_1 U^{*}_2\n\\end{eqnarray}\\]\nThe individual wave intensities are given by \\(I_1=|U_1|^2\\) and \\(I_2=|U_2|^2\\). Using this, we can express each complex wave amplitude in polar form, separating its magnitude (related to intensity) and phase:\n\\[\nU_1=\\sqrt{I_1}e^{i\\phi_1}\n\\] \\[\nU_2=\\sqrt{I_2}e^{i\\phi_2}\n\\]\nSubstituting these expressions back into our interference equation and performing the algebra, the total intensity becomes:\n\\[\nI=I_1+I_2+2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\n\\]\nwhere \\(\\Delta \\phi=\\phi_2-\\phi_1\\) is the phase difference between the waves. This equation is known as the interference formula and contains three terms:\n\n\\(I_1\\) and \\(I_2\\): the individual intensities\n\\(2\\sqrt{I_1 I_2}\\cos(\\Delta \\phi)\\): the interference term that can be positive or negative\n\nA particularly important special case occurs when the interfering waves have equal intensities (\\(I_1=I_2=I_0\\)). The equation then simplifies to:\n\\[\nI=2I_0(1+\\cos(\\Delta \\phi))=4I_0\\cos^2\\left(\\frac{\\Delta \\phi}{2}\\right)\n\\]\nThis last form clearly shows that:\n\nMaximum intensity (\\(4I_0\\)) occurs when \\(\\Delta \\phi = 2\\pi n\\) (constructive interference)\nZero intensity occurs when \\(\\Delta \\phi = (2n+1)\\pi\\) (destructive interference)\nThe intensity varies sinusoidally with the phase difference\n\n\n\n\n\n\n\nConstructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=2\\pi m\\) (where \\(m\\) is an integer), resulting in \\(I=4I_0\\)\n\n\n\n\n\n\n\nConstructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\n\n\n\n\n\nDestructive Interference\n\n\n\nOccurs when \\(\\Delta \\phi=(2m-1)\\pi\\) (where \\(m\\) is an integer), resulting in \\(I=0\\)\n\n\n\n\n\n\n\nDestructive interference of two waves (top, middle) and the sum of the two wave amplitudes (bottom)\n\n\n\n\n\n5.0.1 Phase and Path Difference\nThe phase difference \\(\\Delta \\phi\\) can be related to the path difference \\(\\Delta s\\) between the two waves. For two waves with the same frequency \\(\\omega\\), we can write their complete phase expressions as:\n\\[\\phi_1(\\mathbf{r},t) = \\mathbf{k}_1\\cdot\\mathbf{r} - \\omega t + \\phi_{01}\\] \\[\\phi_2(\\mathbf{r},t) = \\mathbf{k}_2\\cdot\\mathbf{r} - \\omega t + \\phi_{02}\\]\nwhere:\n\n\\(\\mathbf{k}_i\\) are the wave vectors\n\\(\\mathbf{r}\\) is the position vector\n\\(\\omega\\) is the angular frequency\n\\(\\phi_{0i}\\) are initial phase constants\n\nThe instantaneous phase difference is then:\n\\[\n\\Delta\\phi(\\mathbf{r},t) = \\phi_2(\\mathbf{r},t) - \\phi_1(\\mathbf{r},t) = (\\mathbf{k}_2-\\mathbf{k}_1)\\cdot\\mathbf{r} + (\\phi_{02}-\\phi_{01})\n\\]\nFor stationary interference patterns, we typically observe the time-independent phase difference. When the waves travel along similar paths (same direction), this reduces to:\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nwhere \\(\\Delta s\\) is the path difference and \\(\\Delta\\phi_0\\) is any initial phase difference between the sources.\n\n\n\n\n\n\nPhase Difference and Path Difference\n\n\n\nA path difference \\(\\Delta s\\) corresponds to a phase difference \\(k\\Delta s=2\\pi\\Delta s/\\lambda\\). Path differences of integer multiples of \\(\\lambda\\) result in phase differences of integer multiples of \\(2\\pi\\).\n\n\n\n\n5.0.2 Interference of Waves in Space\n\n\n\n\n\nInterference of two plane waves propagating under an angle of 45°. The two left graphs show the original waves. The two right show the total amplitude and the intensity pattern.\n\n\n\n\n\n\n\n\n\nInterference of a spherical wave and a plane wave. The top graphs show the original waves. The two bottom show the total amplitude and the intensity pattern.\n\n\n\n\nThe interference of the spherical and the plane wave (also the one of the two plane waves) give also an interesting result. The intensity resembles to be a snapshot of the shape of the wavefronts of the spherical wave. We can therefore measure the wavefronts of the spherical wave by interfering it with a plane wave. This is also the basic principle behind holography. There we use a reference wave to interfere with the wave that we want to measure. The interference pattern is recorded and can be used to reconstruct the wavefronts of the wave.\n\nA super nice website to try out interference interactively is here.\n\n\n\n5.0.3 Coherence\nIn the earlier consideration we obtained a general description for the phase difference between two waves. TIt is given by and contains the pathlength difference \\(\\Delta s\\) and some intrinsic phase \\(\\Delta\\phi_0\\) that could be part of the wave generation process.\n\\[\\Delta\\phi = k\\Delta s + \\Delta\\phi_0\\]\nTo observe stationary interference, it is important that these two quantities are also stationary, i.e. the phase relation between the two waves is stationary. This relation between the phase of two waves is called coherence and was assumed in all the examples before.\n\n\n\nTwo waves of different frequency over time.\n\n\nThe above image shows the timetrace of the amplitude of two wave with slightly different frequency. Due to the frequency, the waves run out of phase and have acquired a phase different of \\(\\pi\\) after \\(40\\) fs.\nThe temporal coherence of two waves is now defined by the time it takes for the two waves to obtain a phase difference of \\(2\\pi\\). The phase difference between two wave of frequency \\(\\nu_1\\) and \\(\\nu_2\\) is given by\n\\[\n\\Delta \\phi = 2\\pi (\\nu_2-\\nu_1)(t-t_0)\n\\]\nHere \\(t_0\\) refers to the time, when thw two waves were perfectly in sync. Lets assume that the two frequencies are seperarated from a central frequency \\(\\nu_0\\) such that\n\\[\n\\nu_1=\\nu_0-\\Delta \\nu/2\n\\] \\[\n\\nu_2=\\nu_0+\\Delta \\nu/2\n\\]\nInserting this into the first equation yields\n\\[\n\\Delta \\phi = 2\\pi \\Delta \\nu \\Delta t\n\\]\nwith \\(\\Delta t=t-t_0\\). We can now define the coherence time as the time interval over which the phase shift \\(\\Delta \\phi\\) grows to \\(2\\pi\\), i.e. \\(\\Delta \\phi=2\\pi\\). The coherence time is thus\n\\[\n\\tau_{c}=\\Delta t =\\frac{1}{\\Delta \\nu}\n\\]\nThus the temporal coherence and the frequency distribution of the light are intrisincly connected. Monochromatic light has \\(\\Delta nu=0\\) and thus the coherence time is infinitely long. Light with a wide spectrum (white light for example) therefore has and extremly short coherence time.\nThe coherence time is also connected to a coherence length. The coherence length \\(L_c\\) is given by the distance light travels within the coherence time \\(\\tau_c\\), i.e.\n\\[\nL_c=c\\tau_c\n\\]\n\n\n\n\n\n\nCoherence\n\n\n\nTwo waves are called coherent, if they exihibit a fixed phase relation in space or time relation over time. It measures their ability to interfer. The main types of coherence are\n\n5.0.4 Temporal Coherence\n\nMeasures phase correlation of a wave with itself at different times\nCharacterized by coherence time \\(\\tau_c\\) and coherence length \\(L_c = c\\tau_c\\)\nRelated to spectral width: \\(\\tau_c = 1/\\Delta\\nu\\)\nPerfect for monochromatic waves (single frequency)\nLimited for broad spectrum sources (like thermal light)\n\n\n\n5.0.5 Spatial Coherence\n\nMeasures phase correlation between different points in space\nImportant for interference from extended sources\nDetermines ability to form interference patterns\nRelated to source size and geometry\n\nCoherence is a property of the light source and is connected to the frequency distribution of the light. Sources can be:\n\nFully coherent: ideal laser\nPartially coherent: real laser\nIncoherent: thermal light\n\n\n\n\n\n\n\n\n\n\nMore General Description of Coherence\n\n\n\n\n\nWhile the above definition provides an intuitive picture based on frequency spread, we can describe coherence more rigorously using correlation functions. These functions measure how well a wave maintains its phase relationships:\nIn real physical systems, perfect coherence (constant phase relationship) between waves is rare. Partial coherence describes the degree to which waves maintain a consistent phase relationship over time and space. We can characterize this using correlation functions:\n\nTemporal Coherence The complex degree of temporal coherence is given by:\n\n\\[g^{(1)}(\\tau) = \\frac{\\langle U(t)U^*(t+\\tau)\\rangle}{\\sqrt{\\langle|U(t)|^2\\rangle\\langle|U(t+\\tau)|^2\\rangle}}\\]\nwhere:\n\n\\(\\tau\\) is the time delay\n\\(U(t)\\) is the electric field\n\\(\\langle...\\rangle\\) denotes time averaging\n\n\nSpatial Coherence Similarly, spatial coherence between two points is characterized by:\n\n\\[g^{(1)}(\\mathbf{r}_1,\\mathbf{r}_2) = \\frac{\\langle U(\\mathbf{r}_1)U^*(\\mathbf{r}_2)\\rangle}{\\sqrt{\\langle|U(\\mathbf{r}_1)|^2\\rangle\\langle|U(\\mathbf{r}_2)|^2\\rangle}}\\]\nThe obtained correlation functions can be used to calculate the coherence time and length and have the following properties:\n\n\\(|g^{(1)}| = 1\\) indicates perfect coherence\n\\(|g^{(1)}| = 0\\) indicates complete incoherence\n\\(0 &lt; |g^{(1)}| &lt; 1\\) indicates partial coherence\n\nA finite coherence time and length is leads to partial coherence affects interference visibility through:\n\nReduced contrast in interference patterns\nLimited coherence length/area\nSpectral broadening\n\n\n\n\n\n\nTemporal correlation for two waves with slightly different frequencies. The vertical line indicates the coherence time τc = π/Δω.\n\n\n\n\nBesides different frequencies the coherence time can also be affected by phase jumps. The following example shows two waves with the same frequency but multiple phase jumps. The temporal correlation function shows the decoherence due to the phase jumps.\n\n\n\n\n\nTemporal correlation for two waves of same frequency showing decoherence due to multiple phase jumps. Vertical lines indicate positions of phase jumps.\n\n\n\n\n\n\n\nMultiple Wave Interference\nSo far we looked at the interference of two waves, which was a simplification as I mentioned already earlier. Commonly there will be a multitude of partial waves contribute to the oberved intereference. This is what we would like to have a look at now. We will do that in a quite general fashion, as the resulting formulas will appear several times again for different problems.\nNevertheless we will make a difference between\n\nmultiwave interference of waves with the constant amplitude\nmultiwave interference of waves with decreasing amplitude\n\nEspecially the latter is often occuring, if we have multiple reflections and each reflection is only a fraction of the incident amplitude.\n\n\n5.0.6 Multiple Wave Interference with Constant Amplitude\nIn the case of constant amplitude (for example realized by a grating, which we talk about later), the total wave amplitude is given according to the picture below by\n\\[\nU=U_1+U_2+U_1+U_3+\\ldots+U_M\n\\]\nwhere we sum the amplitude over \\(M\\) partial waves. Between the neighboring waves (e.g. \\(U_1\\) and \\(U_2\\)), we will assume a phase difference (because of a path length difference for example), which we denote as \\(\\Delta \\phi\\).\nThe amplitude of the p-th wave is then given by\n\\[\nU_p=\\sqrt{I_0}e^{i(p-1)\\Delta \\phi}\n\\]\nwith the index \\(p\\) being an interger \\(p=1,2,\\ldots,M\\), \\(h=e^{i\\Delta \\phi}\\) and \\(\\sqrt{I_0}\\) as the amplitude of each individual wave. The total amplitude \\(U\\) can be then expressed as\n\\[\nU=\\sqrt{I_0}\\left (1+h+h^2+\\ldots +h^{M-1}\\right)\n\\]\nwhich is a geometric sum. We can apply the sum formula for geometric sums to obtain\n\\[\nU=\\sqrt{I_0}\\frac{1-h^M}{1-h}=\\sqrt{I_0}\\frac{1-e^{iM\\Delta \\phi}}{1-e^{i\\Delta \\phi}}\n\\]\nWe now have to calculate the intensity of the total amplitude\n\\[\nI=|U|^2=I_{0}\\left | \\frac{e^{-iM\\Delta \\phi/2}-e^{iM\\Delta \\phi/2}}{e^{-i\\Delta \\phi/2}-e^{i\\Delta \\phi/2}}\\right |^2\n\\]\nwhich we can further simplify to give\n\\[\nI=I_{0}\\frac{\\sin^2(M\\Delta \\phi/2)}{\\sin^2(\\Delta \\phi/2)}\n\\]\n\n\n\n\n\n\n\nMultiple wave interference of \\(M=6\\) waves with a phase difference of \\(\\phi=\\pi/8\\). The black arrows represent the individual waves, the red arrow the sum of all waves.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.1— Multiple beam interference pattern for M=6 beams. The intensity distribution is shown as a function of the phase shift \\(\\phi\\). The first minimum is at \\(\\phi=2\\pi/M\\). The intensity distribution is symmetric around \\(\\phi=0\\).\n\n\n\n\n\n\n\nThe result is therefore an oscillating function. The numerator \\(\\sin^2(M\\Delta \\phi/2)\\) shows and oscillation frequency, which is by a factor of \\(M\\) higher than the one in the denominator \\(\\sin^2 (\\Delta \\phi/2)\\). Therefore the intensity pattern is oscillating rapidly and creating a first minimum at\n\\[\n\\Delta \\phi=\\frac{2\\pi}{M}\n\\]\nThis is an important result, since it shows that the number of sources \\(M\\) determines the position of the first minimum and the interference peak gets narrower with increasing \\(M\\). Since the phase difference \\(\\Delta \\phi\\) between neighboring sources is the same as for the double slit experiment, i.e. \\(\\Delta \\phi=2\\pi d/\\lambda \\sin(\\theta)\\), we can also determine the angular position of the first minimum. This is given by\n\\[\n\\sin(\\theta_\\textrm{min})=\\frac{1}{M}\\frac{\\lambda}{d}\n\\]\nThis again has the common feature that it scales as \\(\\lambda/d\\). A special situation occurs, whenever the numerator and the denominator become zero. This will happen whenever\n\\[\n\\Delta \\phi=m 2\\pi\n\\]\nwhere \\(m\\) is an integer and denotes the interference order, i.e. the number of wavelength that neighboring partial waves have as path length difference. In this case, the intensity distributiion will give us\n\\[\nI=I_0 \\frac{0}{0}\n\\]\nand we have to determine the limit with the help of l’Hospitals rule. The outcome of this calculation is, that\n\\[\nI(\\Delta \\phi=m2\\Delta \\pi)=M^2 I_0\n\\]\nwhich can be also realized when using the small angle approximation for the sine functions.\n\n5.0.6.1 Wavevector Representation\nWe would like to introduce a different representation of the multiple wave interference of the grating, which is quite insightful. The first order (\\(m=1\\)) constructive interference condition is given by\n\\[\n\\frac{1}{\\lambda}\\sin{\\theta}= \\frac{1}{d}\n\\]\nwhich also means that\n\\[\n\\frac{2\\pi}{\\lambda}\\sin{\\theta}= \\frac{2\\pi}{d}\n\\]\nThis can be written as\n\\[\nk \\sin{\\theta}= K\n\\]\nwhere \\(k\\) is the magnitude of the wavevector of the light and \\(K\\) is the wavevector magnitude that corresponds to the grating period \\(d\\). As the magnitude of the wavevector of the light is conserved, the wavevectors of the incident light and the light traveling along the direction of the first interence peak form the sides of an equilateral triangle. This is shown in the following figure.\n\n\n\n\n\nWavevector summation for the diffraction grating. The wavevector of the incident light \\(k\\) and the wavevector of the light traveling along the direction of the first interference peak \\(K\\) form an equilateral triangle.\n\n\n\n\nThis means that the diffraction grating is providing a wavevector \\(K\\) to alter the direction of the incident light. This is again a common feature reappearing in many situations as for example in the X-ray diffraction of crystals.\n\n\n\n\n\n\nMultiple Wave Interference with Decreasing Amplitude\n\n\n\n\n\nWe will turn our attention now to a slight modification of the previous multiwave interference. We will introduce a decreasing amplitude of the individual waves. The first wave shall have an amplitude \\(U_1=\\sqrt{I_0}\\). The next wave, however, will not only be phase shifted but also have a smaller amplitude.\n\\[\nU_2=h U_1\n\\]\nwhere \\(h=re^{i\\phi}\\) with \\(|h|=r&lt;1\\). \\(r\\) can be regarded as a reflection coefficient, which deminishes the amplitude of the incident wave. According to that the intensity is reduced by\n\\[\nI_2=|U_2|^2=|h U_1|^2=r^2 I_1\n\\]\nThe intensity of the incident wave is multiplied by a factor \\(r^2\\), while the amplitude is multiplied by \\(r\\). Note that the phase factor \\(e^{i\\Delta\\phi}\\) is removed when taking the square of this complex number.\n\n\n\n\n\n\nIntensity at Boundaries\n\n\n\nThe amplitude of the reflected wave is diminished by a factor \\(r\\le 1\\), which is called the reflection coefficient. The intensity is diminished by a factor \\(R=|r|^2\\le1\\), which is the reflectance.\nIn the absence of absorption, reflectance \\(R\\) and transmittance \\(T\\) add to one due to energy conservation.\n\\[\nR+T=1\n\\]\n\n\nConsequently, the third wave would be now \\(U_3=hU_2=h^2U_1\\). The total amplitude is thus\n\\[\nU=U_1+U_2+U_3+\\ldots+U_M = \\sqrt{I_0}(1+h+h^2+\\ldots)\n\\]\n\n\n\n\n\n\nPhase construction of a multiwave intereference with M waves with decreasing amplitude due to a reflection coefficient \\(r=0.95\\).\n\n\n\n\n\n\n\n\n\n\n\nMultiple wave interference with decreasing amplitude. The graph shows the intensity distribution over the phase angle \\(\\phi\\) for different values of the Finesse \\(\\mathcal{F}\\).\n\n\n\n\n\nThis yields again\n\\[\nU=\\sqrt{I_0}\\frac{(1-h^M)}{1-h}=\\frac{\\sqrt{I_0}}{1-r e^{i\\Delta\\phi}}\n\\]\nCalculating the intensity of the waves is giving\n\\[\nI=|U|^2=\\frac{I_{0}}{|1-re^{i\\Delta\\phi}|^2}=\\frac{I_0}{(1-r)^2+4r\\sin^2(\\Delta\\phi/2)}\n\\]\nwhich is also known as the Airy function. This function can be further simplified by the following abbrevations\n\\[\nI_{\\rm max}=\\frac{I_0}{(1-r)^2}\n\\]\nand\n\\[\n\\mathcal{F}=\\frac{\\pi \\sqrt{r}}{1-r}\n\\]\nwhere the latter is called the Finesse. With those abbrevations, we obtain\n\\[\nI=\\frac{I_{\\rm max}}{1+4\\left(\\frac{\\mathcal{F}}{\\pi}\\right)^2\\sin^{2}(\\Delta\\phi/2)}\n\\]\nfor the interference of multiple waves with decreasing amplitude.\nThis intensity distribution has a different shape than the one we obtained for multiple waves with the same amplitude.\nWe clearly observe that with increasing Finesse the intensity maxima, which occur at multiples fo \\(\\pi\\) get much narrower. In addition the regions between the maxima show better contrast and fopr higher Finesse we get complete destructive interference.\n\n\n\n\n\n\n5.0.7 Light beating\n\n5.0.7.1 Beating of two waves\nLet us consider now interference in the time domain. We introduce two monochromatic waves of frequencies \\(\\nu_1\\) and \\(\\nu_2\\). We will denote their amplitudes by \\(\\sqrt{I_1}\\) and \\(\\sqrt{I_2}\\).\nThe total amplitude is thus\n\\[\nU=U_1+U_2 = \\sqrt{I_1} \\exp(i2\\pi\\nu_1 t) + \\sqrt{I_2} \\exp(i2\\pi\\nu_2 t)\n\\]\nsuch that we obtain an Intensity\n\\[\nI=|U|^2 = I_1 + I_2 + 2\\sqrt{I_1I_2}\\cos(2\\pi(\\nu_1-\\nu_2)t)\n\\]\nThe intensity is thus time dependent and oscillates at a frequency \\(\\nu_1-\\nu_2\\), which is the so-called beating frequency. Similar schemes are used in optical heterodyne detection but also in acoustics when tuning your guitar.\n\n\n5.0.7.2 Multiple wave beating and pulse generation\nConsider now a whole set of \\(M=2L+1\\) each with an amplitude \\(\\sqrt{I_0}\\). The frequencies of the waves are given by \\(\\nu_q=\\nu_0+q\\Delta\\nu\\) with \\(q=-L,\\dots,L\\) with \\(\\nu_0\\) beeing the center frequency of the spectrum and \\(\\Delta \\nu\\) the frequency spacing. We will assume that \\(\\Delta nu&lt;&lt;\\nu_0\\) such that the total amplitude of the waves is given by\n\\[\nU=\\sum_{q=-L}^L \\sqrt{I_0} \\exp(i2\\pi(\\nu_0+q\\Delta\\nu)t)\n\\]\nThe total intensity can then be calculated in the same way as for the multiple source in space before. Using \\(\\phi=2\\pi \\Delta \\nu t\\) we obtained \\[\nI(t)=I_0 \\frac{\\sin^2(M\\pi t/T)}{\\sin^2(\\pi t/T)}\n\\]\nwith \\(T=1/\\Delta\\nu\\) and a maximum intensity of \\(I_{\\rm max}=M^2 I_0\\).\n\n\n\n\n\n\n\n\nFigure 5.2— Multiple wave beating with M=1000 monochromatic waves separated by Δν=1 GHz. The intensity oscillates with period T=1/Δν=1 ns. Each pulse has a width of approximately T/M=1 ps with maximum intensity I_max=M²I₀.\n\n\n\n\n\n\n\n\n5.0.8 Frequency Combs: Phase-Coherent Temporal Interference\nThe pulse generation we just examined leads us to an important concept in modern optics: frequency combs. A frequency comb is a spectrum consisting of a series of discrete, equally spaced frequency lines that results from a train of phase-coherent pulses in the time domain.\n\n5.0.8.1 From Pulse Trains to Frequency Combs\nLet’s extend our understanding of multiple wave beating to include phase coherence. When we have a set of equidistant frequency components that maintain a fixed phase relationship, the resulting time-domain signal is a periodic train of pulses. Conversely, a periodic train of pulses in the time domain corresponds to a frequency comb in the spectral domain.\nThe relationship between these domains is described by the Fourier transform. For a pulse train with repetition rate \\(f_{rep} = \\Delta\\nu\\) (the spacing between frequency components), the frequency spectrum consists of lines at:\n\\[f_n = f_0 + n \\cdot f_{rep}\\]\nwhere \\(f_0\\) is the carrier-envelope offset frequency and \\(n\\) is an integer.\n\n\n5.0.8.2 Mathematical Description\nConsider a train of pulses described by the electric field:\n\\[E(t) = \\sum_{m=-\\infty}^{\\infty} A(t - m T_{rep}) e^{i[\\omega_c(t - m T_{rep}) + \\phi_{CE} \\cdot m + \\phi_0]}\\]\nwhere: - \\(A(t)\\) is the pulse envelope - \\(T_{rep} = 1/f_{rep}\\) is the pulse repetition period - \\(\\omega_c\\) is the carrier frequency - \\(\\phi_{CE}\\) is the carrier-envelope phase slip (the phase shift from pulse to pulse) - \\(\\phi_0\\) is a constant phase\nThe Fourier transform of this pulse train gives us a frequency comb with:\n\\[f_0 = \\frac{\\phi_{CE}}{2\\pi} \\cdot f_{rep}\\]\nThis carrier-envelope offset frequency (\\(f_0\\)) is crucial for determining the absolute positions of the comb lines.\n\n\n\n\n\n\n\n\nFigure 5.3— Demonstration of a frequency comb. (Left) Time domain representation showing a train of phase-coherent pulses. (Right) Frequency domain representation showing equally spaced frequency lines forming a comb structure.\n\n\n\n\n\n\n\n5.0.8.3 Applications of Frequency Combs\nFrequency combs have revolutionized precision measurements in physics and enabled numerous applications:\n\nOptical Clocks: Frequency combs provide a “gear mechanism” to count optical frequencies, enabling optical atomic clocks that are orders of magnitude more precise than conventional atomic clocks.\nPrecision Spectroscopy: The precise and stable frequency references allow for high-resolution molecular spectroscopy.\nCalibration of Astronomical Spectrographs: Frequency combs enable the detection of Earth-like exoplanets by providing precise wavelength calibration for astronomical instruments.\nDistance Measurements: They enable precise absolute distance measurements used in applications from gravitational wave detectors to satellite formation flying.\nTelecommunications: Frequency combs can be used for wavelength-division multiplexing in optical communications.\n\n\n\n5.0.8.4 Connection to Mode-Locked Lasers\nIn practice, frequency combs are often generated using mode-locked lasers. In such lasers, multiple longitudinal modes of the laser cavity oscillate with a fixed phase relationship, resulting in short pulses. The Fourier transform of these regularly spaced pulses is precisely the frequency comb.\nThe mode-locking can be achieved through various mechanisms:\n\nActive mode-locking: Using an external modulator driven at the cavity round-trip frequency\nPassive mode-locking: Using saturable absorbers or Kerr-lens mode-locking\n\nThe 2005 Nobel Prize in Physics was awarded to Theodor W. Hänsch and John L. Hall for their contributions to the development of laser-based precision spectroscopy, including the optical frequency comb technique.\n\n\n5.0.8.5 The Fundamental Link Between Time and Frequency Domains\nFrequency combs beautifully illustrate the duality between time and frequency domains in physics. A perfectly periodic sequence of events in time (the pulse train) corresponds to discrete, equally spaced frequencies. The more precise and stable the temporal pattern, the more precise and stable the frequency components.\nThis duality is fundamental to many areas of physics and engineering, from quantum mechanics to signal processing, and frequency combs represent one of its most elegant and useful manifestations in optics.",
    "crumbs": [
      " Lecture 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>just for plotting later</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/01-lecture04.html",
    "href": "lectures/lecture04/01-lecture04.html",
    "title": "6  Introduction to Gaussian Beams",
    "section": "",
    "text": "In optics and laser physics, Gaussian beams represent one of the most fundamental and important mathematical descriptions of laser light propagation. They are particularly relevant for understanding laser resonators, optical systems, and coherent light behavior. This section introduces Gaussian beams from first principles and explores their mathematical description.\n\n6.0.1 Derivation from the Helmholtz Equation\nWe begin with the Helmholtz equation, which describes monochromatic electromagnetic waves in a homogeneous medium:\n\\[\\nabla^2 U + k^2 U = 0\\]\nwhere \\(U\\) represents the electric field component, \\(k = 2\\pi/\\lambda\\) is the wave number, and \\(\\lambda\\) is the wavelength of light. For a wave predominantly traveling along the \\(z\\)-axis, we can express the electric field as:\n\\[U(x,y,z) = u(x,y,z)e^{-ikz}\\]\nHere, \\(u(x,y,z)\\) is a complex amplitude function that varies slowly with \\(z\\) compared to the wavelength. Substituting this into the Helmholtz equation and expanding the Laplacian operator yields:\n\\[\\left(\\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2} + \\frac{\\partial^2}{\\partial z^2}\\right)(u e^{-ikz}) + k^2 (u e^{-ikz}) = 0\\]\nComputing the derivatives and simplifying:\n\\[\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} + \\frac{\\partial^2 u}{\\partial z^2} - 2ik\\frac{\\partial u}{\\partial z} = 0\\]\n\n\n6.0.2 The Paraxial Approximation\nThe paraxial approximation applies when the beam’s angular spread is small, meaning the wavefronts are nearly perpendicular to the propagation axis. Mathematically, this means that the amplitude \\(u\\) varies slowly along the propagation direction compared to transverse directions:\n\\[\\left|\\frac{\\partial^2 u}{\\partial z^2}\\right| \\ll \\left|2k\\frac{\\partial u}{\\partial z}\\right|\\]\nUnder this approximation, the Helmholtz equation simplifies to the paraxial Helmholtz equation:\n\\[\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} - 2ik\\frac{\\partial u}{\\partial z} = 0\\]\nTo solve this equation, we propose the ansatz:\n\\[u(x,y,z) = A(z)\\exp\\left[-\\frac{k}{2q(z)}(x^2 + y^2)\\right]\\]\nwhere \\(A(z)\\) and \\(q(z)\\) are complex functions to be determined. Substituting this into the paraxial equation and solving the resulting differential equations:\n\\[\\frac{dq}{dz} = 1 \\quad \\text{and} \\quad \\frac{dA}{dz} = -\\frac{A}{q}\\]\nThese yield solutions \\(q(z) = q_0 + z\\) and \\(A(z) = \\frac{A_0}{q(z)}\\), where \\(q_0\\) and \\(A_0\\) are constants.\nThe complex beam parameter \\(q(z)\\) relates to physical parameters through:\n\\[\\frac{1}{q(z)} = \\frac{1}{R(z)} - i\\frac{\\lambda}{\\pi w^2(z)}\\]\nwhere \\(R(z)\\) is the radius of curvature of the wavefront and \\(w(z)\\) is the beam radius at which the intensity falls to \\(1/e^2\\) of its axial value.\nSetting \\(q_0 = iz_0\\) where \\(z_0\\) is the Rayleigh range, we can express these parameters as:\n\\[w(z) = w_0\\sqrt{1 + \\left(\\frac{z}{z_0}\\right)^2}\\]\n\\[R(z) = z\\left[1 + \\left(\\frac{z_0}{z}\\right)^2\\right]\\]\nwhere \\(w_0 = \\sqrt{\\frac{\\lambda z_0}{\\pi}}\\) is the beam waist (minimum beam radius).\nThe complete Gaussian beam solution is:\n\\[U(x,y,z) = U_0 \\frac{w_0}{w(z)} \\exp\\left[-\\frac{x^2 + y^2}{w^2(z)}\\right] \\exp\\left[-ikz - ik\\frac{x^2 + y^2}{2R(z)} + i\\phi(z)\\right]\\]\nwhere \\(\\phi(z) = \\arctan(z/z_0)\\) is the Gouy phase shift, representing an additional phase beyond that of a plane wave.\nIn scalar wave theory, the intensity of the Gaussian beam is proportional to the square of the amplitude. It can be calculated as:\n\\[I(x,y,z) = |U(x,y,z)|^2 = I_0\\frac{w_0^2}{w^2(z)}\\exp\\left[-\\frac{2(x^2+y^2)}{w^2(z)}\\right]\\]\nwhere \\(I_0 = |U_0|^2\\) is the peak intensity at the beam waist. This expression shows that the intensity has a Gaussian profile in any transverse plane, with its peak on the beam axis. The intensity falls to \\(1/e^2\\) of its axial value at a radial distance \\(r = w(z)\\) from the axis, which defines the beam radius. The total power carried by the beam is conserved during propagation, but the peak intensity decreases as \\(w(z)\\) increases with distance from the waist.\n\n\n\n\n\n\nGaussian Beam Propagation in the x-z Plane\n\n\n\nWe can visualize how a Gaussian beam’s intensity varies across both the propagation direction (z-axis) and transverse direction (x-axis) simultaneously using a 2D contour plot.\n\n\n\n\n\n\n\n\nFigure 6.1— Gaussian Beam Intensity Distribution in the x-z Plane for a wavelength of 632.8 nm and a beam waist of \\(w_0=0.1\\, \\text{mm}\\)\n\n\n\n\n\nThis contour plot illustrates how the Gaussian beam intensity distribution evolves as it propagates. The horizontal axis represents the normalized propagation distance (z/z₀), while the vertical axis shows the normalized transverse distance (x/w₀). The color gradient indicates intensity values, with brighter colors representing higher intensities.\nThe white dashed lines trace the beam width w(z), where the intensity falls to 1/e² (approximately 13.5%) of its value on the beam axis. Note how the beam width reaches its minimum at the beam waist (z=0) and expands as the beam propagates away from the focus.\nThe plot clearly shows that the highest intensity occurs at the beam waist, with the intensity decreasing both as we move away from the center axis and as the beam propagates away from the focal point.\n\n\n\n6.0.2.1 Key Gaussian Beam Parameters\nThe following table summarizes the important parameters that characterize a Gaussian beam:\n\n\n\n\n\n\n\n\nParameter\nExpression\nDescription\n\n\n\n\nBeam waist (\\(w_0\\))\n\nMinimum beam radius at focus (\\(z=0\\))\n\n\nBeam width (\\(w(z)\\))\n\\(w(z) = w_0\\sqrt{1 + \\left(\\frac{z}{z_0}\\right)^2}\\)\nBeam radius at position \\(z\\)\n\n\nRayleigh length (\\(z_0\\))\n\\(z_0 = \\frac{\\pi w_0^2}{\\lambda}\\)\nDistance over which beam area doubles\n\n\nRadius of curvature (\\(R(z)\\))\n\\(R(z) = z\\left[1 + \\left(\\frac{z_0}{z}\\right)^2\\right]\\)\nRadius of wavefront curvature\n\n\nDivergence angle (\\(\\theta\\))\n\\(\\theta = \\frac{\\lambda}{\\pi w_0}\\)\nFar-field half-angle of beam spread\n\n\nGouy phase (\\(\\phi(z)\\))\n\\(\\phi(z) = \\arctan\\left(\\frac{z}{z_0}\\right)\\)\nAdditional phase beyond plane wave\n\n\nComplex beam parameter (\\(q(z)\\))\n\\(q(z) = z + iz_0\\)\nCombined parameter for beam properties\n\n\n\nThese parameters are interrelated, forming a complete description of how a Gaussian beam propagates. The Rayleigh length \\(z_0\\) is particularly important as it defines the transition between the near field (where the beam is approximately collimated) and the far field (where the beam diverges linearly). At a distance of one Rayleigh length from the waist, the beam width increases by a factor of \\(\\sqrt{2}\\) and the intensity drops to half its maximum value.\n\n\n\n\n\n\nGaussian Beam Intensity Profiles\n\n\n\nTo better understand the spatial distribution of intensity in a Gaussian beam, it’s helpful to visualize how the intensity varies along different directions. Here we explore two fundamental cross-sections: the axial intensity along the beam propagation path, and the transverse intensity profile at the beam waist.\n\n\n\n\n\n\n\n\nFigure 6.2— Gaussian Beam Intensity Profiles for a wavelenght of 632.8 nm and a beam waist of \\(w_0=0.1\\, m\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nGaussian Beam Propagation\n\n\n\nTo better understand the spatial evolution of a Gaussian beam as it propagates, we can visualize how two key parameters change with distance: the beam width \\(w(z)\\) and the wavefront radius of curvature \\(R(z)\\).\n\n\n\n\n\n\n\n\nFigure 6.3— Gaussian Beam Width and Wavefront Curvature for a wavelength of 632.8 nm and a beam waist of \\(w_0=0.1\\, \\text{mm}\\)\n\n\n\n\n\nThe left plot shows how the beam width \\(w(z)\\) evolves with distance from the beam waist. At \\(z = 0\\), the beam is at its narrowest point \\(w_0\\). At the Rayleigh range (\\(z = ±z_0\\)), the width increases to \\(\\sqrt{2}w_0\\). For \\(|z| \\gg z_0\\), the beam width increases approximately linearly with distance, corresponding to a constant far-field divergence angle \\(\\theta = \\lambda/(\\pi w_0)\\).\nThe right plot illustrates the wavefront radius of curvature \\(R(z)\\). At the beam waist, the wavefronts are flat (\\(R = \\infty\\)). The curvature reaches its minimum absolute value of \\(2z_0\\) at \\(z = ±z_0\\). For \\(z &gt; 0\\), \\(R(z)\\) is positive (converging wavefronts), while for \\(z &lt; 0\\), \\(R(z)\\) is negative (diverging wavefronts). As \\(|z|\\) increases, \\(R(z)\\) approaches the asymptotic behavior of a spherical wave, where \\(R(z) \\approx z\\).\nThese parameters together provide a complete description of how the Gaussian beam transforms from a tightly focused wave near the waist to an approximately spherical wave in the far field.\n\n\n\n\n\n6.0.3 Gaussian Beam Transformation Through Optical Systems\n\n6.0.3.1 The ABCD Matrix Formalism\nThe propagation of Gaussian beams through optical systems can be elegantly described using the ABCD matrix formalism from ray optics. While ray optics typically tracks the position and angle of rays, for Gaussian beams we track the transformation of the complex beam parameter \\(q(z)\\).\nWhen a Gaussian beam passes through an optical system characterized by an ABCD matrix, the complex beam parameter transforms according to:\n\\[q_2 = \\frac{Aq_1 + B}{Cq_1 + D}\\]\nwhere \\(q_1\\) is the initial complex beam parameter and \\(q_2\\) is the transformed parameter. This remarkable result, known as the ABCD law for Gaussian beams, allows us to determine how the beam waist and wavefront curvature change through arbitrary optical systems.\n\n\n6.0.3.2 Common Optical Elements\nDifferent optical elements transform Gaussian beams in characteristic ways:\n\nFree-space propagation over distance \\(d\\) is represented by:\n\\[\\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix} = \\begin{pmatrix} 1 & d \\\\ 0 & 1 \\end{pmatrix}\\]\nThis matrix describes how the beam naturally diverges as it propagates.\nThin lens with focal length \\(f\\):\n\\[\\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -1/f & 1 \\end{pmatrix}\\]\nA lens modifies the wavefront curvature without changing the beam diameter at the lens location.\nCurved interface between media with refractive indices \\(n_1\\) and \\(n_2\\) and radius of curvature \\(R\\):\n\\[\\begin{pmatrix} A & B \\\\ C & D \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{n_2-n_1}{n_2 R} & \\frac{n_1}{n_2} \\end{pmatrix}\\]\n\nMultiple optical elements can be analyzed by multiplying their respective ABCD matrices in the order encountered by the beam.\n\n\n6.0.3.3 Focusing of Gaussian Beams\nA particularly important case is the focusing of a Gaussian beam by a lens. If a collimated Gaussian beam with waist \\(w_0\\) is incident on a lens with focal length \\(f\\), the focused beam will have a new waist:\n\\[w_0' = \\frac{\\lambda f}{\\pi w_0}\\]\nlocated approximately at the focal point. This equation highlights the fundamental diffraction limit of focusing: smaller focal spots require larger input beam diameters relative to the wavelength.\nWhen a Gaussian beam is focused by a lens, the Rayleigh range of the focused beam also changes. For a collimated input beam, the new Rayleigh range after focusing is:\n\\[z_0' = \\frac{\\pi {w_0'}^2}{\\lambda} = \\frac{\\lambda f^2}{\\pi w_0^2}\\]\nThis means that tightly focused beams (small \\(w_0'\\)) have correspondingly shorter Rayleigh ranges, resulting in more rapid divergence beyond the focal point. This inverse relationship between spot size and Rayleigh range represents a fundamental trade-off in beam focusing: achieving a smaller spot size necessarily results in a beam that diverges more quickly after the focus.\nThe divergence angle of the focused beam is also affected, increasing as the spot size decreases:\n\\[\\theta' = \\frac{\\lambda}{\\pi w_0'} = \\frac{w_0}{f}\\]\nThis relationship shows that the focused beam’s divergence is inversely proportional to the input beam width. A wider input beam produces a more tightly focused spot with greater divergence, while a narrower input beam creates a larger focal spot with less divergence.\nThe transformation matrices enable us to design optical systems that reshape Gaussian beams to desired specifications—expanding, collimating, or focusing them for specific applications. This matrix approach bridges ray optics and wave optics, providing a powerful tool for optical system design with coherent light sources.\n\n\n\n6.0.4 Higher-Order Gaussian Modes\n\n6.0.4.1 Hermite-Gaussian Beams\nHermite-Gaussian modes form a complete set of solutions to the paraxial wave equation in Cartesian coordinates. They can be expressed as:\n\\[U_{nm}(x,y,z) = U_0\\frac{w_0}{w(z)}H_n\\left(\\frac{\\sqrt{2}x}{w(z)}\\right)H_m\\left(\\frac{\\sqrt{2}y}{w(z)}\\right) \\exp\\left[-\\frac{x^2 + y^2}{w^2(z)}\\right]\\] \\[\\times \\exp\\left[-ikz - ik\\frac{x^2 + y^2}{2R(z)} + i(n+m+1)\\phi(z)\\right]\\]\nwhere \\(H_n\\) and \\(H_m\\) are Hermite polynomials of orders \\(n\\) and \\(m\\). The indices \\(n,m = 0,1,2,...\\) determine the number of nodes in the intensity pattern along \\(x\\) and \\(y\\) directions. The fundamental Gaussian beam corresponds to \\(n=m=0\\).\nThese modes naturally arise in laser resonators with rectangular symmetry and maintain their intensity pattern during propagation, though they scale in size. Each higher-order mode experiences an additional Gouy phase shift, causing different modes to accumulate phase at different rates during propagation.\n\n\n\n\n\n\n\n\nFigure 6.4— Intensity (top row) and phase (bottom row) distributions of the first four Hermite-Gaussian modes in the xy-plane at z=1z₀: (a) HG₀₀, (b) HG₁₀, (c) HG₀₁, and (d) HG₁₁. Higher-order modes clearly show multiple intensity peaks.\n\n\n\n\n\n\n\n6.0.4.2 Laguerre-Gaussian Beams\nIn systems with cylindrical symmetry, Laguerre-Gaussian modes provide a more natural description. In cylindrical coordinates \\((r,\\theta,z)\\), they are given by:\n\\[U_{pl}(r,\\theta,z) = U_0\\frac{w_0}{w(z)}\\left(\\frac{\\sqrt{2}r}{w(z)}\\right)^{|l|}L_p^{|l|}\\left(\\frac{2r^2}{w^2(z)}\\right) \\exp\\left[-\\frac{r^2}{w^2(z)}\\right]\\] \\[\\times \\exp\\left[-ikz - ik\\frac{r^2}{2R(z)} + i(2p+|l|+1)\\phi(z) + il\\theta\\right]\\]\nwhere \\(L_p^{|l|}\\) are the associated Laguerre polynomials, \\(p \\geq 0\\) is the radial index determining the number of radial nodes, and \\(l\\) is the azimuthal index that determines the helical structure of the wavefront.\nA remarkable property of Laguerre-Gaussian modes with \\(l \\neq 0\\) is that they carry orbital angular momentum (OAM) of \\(l\\hbar\\) per photon. This OAM arises from the helical phase structure represented by the term \\(\\exp(il\\theta)\\), which creates a twisted wavefront resembling a spiral staircase. The intensity distribution forms a ring-like pattern with a dark center for \\(l \\neq 0\\) due to the phase singularity along the beam axis. As \\(p\\) increases, additional concentric rings appear in the intensity pattern.\n\n\n\n\n\n\n\n\nFigure 6.5— Intensity (top row) and phase (bottom row) distributions of the first four Laguerre-Gaussian modes in the xy-plane at z=0.1z₀: (a) LG₀₀, (b) LG₀₁, (c) LG₁₀, and (d) LG₁₁. Note the ring-like intensity patterns and spiral phase structures in modes with non-zero azimuthal index l.\n\n\n\n\n\nThe orbital angular momentum of light is distinct from spin angular momentum (SAM), which is associated with circular polarization (±\\(\\hbar\\) per photon). While SAM relates to the polarization state of light, OAM relates to the spatial structure of the wavefront. Importantly, these two forms of angular momentum can interact through spin-orbit coupling in certain optical systems, particularly in anisotropic or inhomogeneous media, at interfaces, or when light experiences strong focusing. Such spin-orbit coupling enables novel phenomena like spin-to-orbital angular momentum conversion, where the polarization state can influence the spatial structure of the beam and vice versa. This coupling mechanism has found specific applications in:\n\nOptical tweezers - Spin-orbit coupling allows precise control of trapped particles by converting polarization changes into rotational motion, enabling manipulation of microscopic objects with unprecedented precision.\nQuantum cryptography - The coupling between SAM and OAM creates additional degrees of freedom for encoding quantum information, enhancing the security and information capacity of quantum key distribution protocols.\nOptical vortex metrology - Using the phase singularities created by spin-orbit interactions to detect nanoscale surface imperfections with superior sensitivity compared to conventional techniques.\nChiral spectroscopy - The interaction between polarization and spatial modes enables enhanced detection of chiral molecules by amplifying the difference in light-matter interactions between enantiomers.\nStructured light microscopy - Coupling between SAM and OAM generates complex field patterns that improve resolution beyond the diffraction limit in specific imaging configurations.\n\nBoth families of higher-order modes are important in modern optics applications, including optical manipulation, quantum information processing, and mode-division multiplexing in optical communications. They represent different orthogonal bases of the same solution space and can be transformed into each other through appropriate optical systems.",
    "crumbs": [
      " Lecture 4",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/01-lecture05.html",
    "href": "lectures/lecture05/01-lecture05.html",
    "title": "7  Introduction to Fourier Optics",
    "section": "",
    "text": "Fourier optics offers a robust analytical approach to understanding light propagation through optical systems by employing Fourier analysis techniques on optical fields. This framework elegantly connects image formation and optical resolution to the transmission of spatial information via light waves. Our exploration begins with examining complex transmittance functions, which give us fundamental insights into how various samples shape optical wavefronts. From this foundation, we will progress to the essential principles of Fourier optics and the associated diffraction integrals.\n\n7.0.1 Transmission\nWhen light interacts with an optical component or object, its amplitude and phase can be modified. Following Saleh and Teich’s formalism, we can characterize this interaction using the complex transmission factor \\(t(x,y)\\), which is defined as the ratio of the output field amplitude to the input field amplitude at each point \\((x,y)\\) in a plane:\n\\[t(x,y) = \\frac{U_{\\text{out}}(x,y)}{U_{\\text{in}}(x,y)}\\]\nThis transmission factor is generally complex-valued, with its magnitude representing amplitude modulation and its phase representing phase modulation of the incident light.\nFor a thin lens, the primary effect is phase modulation. To derive the transmission function for a thin lens, we need to consider the optical path length through the lens at each point. Consider a planoconvex lens with one flat surface and one spherical surface of radius \\(R\\). The thickness of the lens varies with position according to:\n\\[d(x,y) = d_0 - \\frac{(x^2+y^2)}{2R}\\]\nwhere \\(d_0\\) is the thickness at the center. As light passes through the lens, it experiences a phase delay proportional to the optical path length, which is the product of the refractive index \\(n\\) and the physical path length:\n\\[\\phi(x,y) = k \\cdot n \\cdot d(x,y) - k \\cdot d(x,y)_{\\text{air}}\\]\nwhere \\(k = 2\\pi/\\lambda\\) is the wavenumber. Simplifying:\n\\[\\phi(x,y) = k(n-1)d(x,y) = k(n-1)\\left(d_0 - \\frac{(x^2+y^2)}{2R}\\right)\\]\nThe first term represents a constant phase shift that we can ignore, and the second term gives us the position-dependent phase modulation. For a lens with focal length \\(f\\), the relationship between \\(R\\) and \\(f\\) is given by the lensmaker’s formula, which for a planoconvex lens simplifies to:\n\\[(n-1)\\frac{1}{R} = \\frac{1}{f}\\]\nSubstituting this into our phase equation:\n\\[\\phi(x,y) = -k(n-1)\\frac{(x^2+y^2)}{2R} = -k\\frac{(x^2+y^2)}{2f}\\]\nThe complex transmission factor is then:\n\\[t(x,y) = \\exp[j\\phi(x,y)] = \\exp\\left[-j\\frac{k}{2f}(x^2+y^2)\\right]\\]\nThis quadratic phase factor represents the position-dependent phase delay introduced by the lens, with greater delays at the thicker portions of the lens.\n\n\n\n\n\n\n\n\nFigure 7.1— Phase modulation effect of a thin lens on an incident plane wave. (a) The quadratic phase profile introduced by the lens at z=0. (b) The wavefront shape in the x-z plane after passing through the lens, showing how the initially flat wavefront is transformed into a converging spherical wavefront.\n\n\n\n\n\nThis transmission function is crucial in Fourier optics as it allows us to mathematically model how a lens transforms an incident field. When placed in the path of a light wave, the lens modifies the wavefront according to this transmission factor, effectively performing a spatial Fourier transform of the input field at its focal plane.\n\n\n7.0.2 Generalization to Arbitrary Thickness Objects\nFor arbitrary thickness objects, we can extend our treatment beyond the thin-element approximation. When light propagates through a medium of varying thickness and refractive index, the transmission function becomes:\n\\[t(x,y) = A(x,y) e^{i\\phi(x,y)}\\]\nwhere \\(A(x,y)\\) represents amplitude modulation (absorption or gain) and \\(\\phi(x,y)\\) represents phase modulation. For a thick object, the phase shift is given by the path integral through the object:\n\\[\\phi(x,y) = k \\int_\\text{path} [n(x,y,z) - n_0] dz\\]\nwhere \\(n(x,y,z)\\) is the spatially varying refractive index within the object, \\(n_0\\) is the refractive index of the surrounding medium, and the integration is performed along the light path through the object.\nThis formulation accounts for complex three-dimensional objects where both the thickness and the refractive index may vary with position. For inhomogeneous media, we can express the transmission function as:\n\\[t(x,y) = \\exp\\left[ -\\frac{1}{2}\\alpha(x,y) + i k\\int_0^{d(x,y)} n(x,y,z)dz \\right]\\]\nwhere \\(\\alpha(x,y)\\) is the absorption coefficient integrated along the path, and \\(d(x,y)\\) is the thickness at position \\((x,y)\\).\nFor many practical applications, this can be approximated by considering the effective phase and amplitude changes, leading to the more manageable form:\n\\[t(x,y) = \\tau(x,y) e^{i k(n-n_0)d(x,y)}\\]\nwhere \\(\\tau(x,y)\\) is the amplitude transmission coefficient accounting for reflection and absorption losses.\nThis mathematical framework will become crucially important later when we describe image formation from waves that have propagated through an object. The transmission function directly encodes how an object modifies both the amplitude and phase of the incident light field, which determines how the object appears in an imaging system. Different imaging modalities (such as bright-field, phase-contrast, or differential interference contrast microscopy) essentially measure different aspects of this complex transmission function, revealing different properties of the object being imaged.\n\n\n7.0.3 Wave Propagation Through Objects\nWhen a plane wave propagating along the z-axis encounters an object, its wavefronts are modified according to the object’s transmission function. This section explores how different types of objects transform incident wavefronts, which is fundamental to understanding phenomena from simple refraction to complex wavefront shaping.\n\n\n\n\n\n\n\n\nFigure 7.2— Wavefront propagation after transmission through different optical elements. (a) A plane wave passing through free space maintains flat wavefronts. (b) After passing through a converging lens, the wavefronts become spherical, converging toward the focal point. (c) Transmission through a prism tilts the wavefronts, changing the propagation direction. (d) A phase plate with arbitrary phase profile creates custom-shaped wavefronts.\n\n\n\n\n\nThe wavefront visualizations above illustrate how different optical elements transform an incident plane wave:\n\nFree Space Propagation: In the absence of any optical element, a plane wave maintains flat wavefronts perpendicular to the propagation direction.\nLens Effect: A converging lens introduces a quadratic phase modulation, transforming plane wavefronts into converging spherical wavefronts that focus at the focal point.\nPrism Effect: A prism applies a linear phase gradient across the wavefront, tilting the wavefronts and changing the propagation direction according to Snell’s law.\nArbitrary Phase Objects: More complex phase profiles create correspondingly complex wavefront shapes, which can be designed for specific applications like wavefront correction or beam shaping.\n\nUnderstanding these wavefront transformations is essential in optical system design, as the shape of the wavefront directly determines how light propagates through subsequent optical elements and ultimately forms images or interference patterns.\n\n\n7.0.4 Spatial Frequencies and Angular Spectrum\nBuilding on our analysis of wave propagation through various optical elements, we now explore a fundamental concept in Fourier optics that connects spatial patterns to wave propagation directions. This relationship between spatial structure and angular distribution is a direct extension of how different optical elements transform wavefronts, as visualized in the previous section. Just as a lens converts a plane wave into a converging spherical wave and a prism tilts the wavefront to change the propagation direction, complex spatial patterns decompose into multiple propagation directions—a relationship that will become essential when we discuss optical imaging systems, diffraction limits, and the resolution capabilities of microscopes and telescopes.\n\n\n\n\n\n\n\n\nFigure 7.3— Spatial frequency analysis of an image. (a) Original grayscale image. (b) Magnitude of the 2D Fourier transform, showing the distribution of spatial frequencies. (c) Phase of the Fourier transform.\n\n\n\n\n\n\n7.0.4.1 The Concept of Spatial Frequencies\nJust as a temporal signal can be decomposed into frequency components through Fourier analysis, a spatial pattern or object can be represented as a superposition of spatial harmonic functions with different spatial frequencies. The spatial frequency \\(\\nu\\) represents how rapidly the intensity or phase of an optical field changes with distance.\nFor a two-dimensional complex spatial harmonic function:\n\\[f(x,y) = A e^{i 2\\pi(\\nu_x x + \\nu_y y)}\\]\nwhere:\n\n\\(\\nu_x\\) and \\(\\nu_y\\) are the spatial frequencies in the x and y directions (in cycles per unit length)\n\\(A\\) is the complex amplitude\n\nHigher spatial frequencies correspond to finer details in an object, while lower spatial frequencies represent coarser features.\nOverall, the function \\(f(x,y)\\) can be expressed as the Fourier transform of its spatial frequency components:\n\\[f(x,y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} F(\\nu_x, \\nu_y) e^{i 2\\pi(\\nu_x x + \\nu_y y)} d\\nu_x d\\nu_y\\]\nwhere \\(F(\\nu_x, \\nu_y)\\) is the spatial frequency spectrum of \\(f(x,y)\\).\n\n\n\n\n\n\nFourier Transform Review\n\n\n\n\n\n\n7.0.5 Basic Definitions\nThe Fourier transform decomposes a function into its constituent frequencies. For a function \\(f(x)\\), its Fourier transform \\(F(k)\\) is defined as:\n\\[F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{-ikx} dx\\]\nThe inverse Fourier transform reconstructs the original function:\n\\[f(x) = \\int_{-\\infty}^{\\infty} F(k) e^{ikx} dk\\]\nIn optics, \\(x\\) typically represents spatial coordinates and \\(k\\) represents spatial frequencies. When working with discrete data, as you will in your computational exercises, you’ll use the Discrete Fourier Transform (DFT), which is efficiently computed using the Fast Fourier Transform (FFT) algorithm:\n\n\n\n\n\n\n\n\n\n\n\n7.0.6 Important Properties\n\nLinearity: \\(\\mathcal{F}\\{af(x) + bg(x)\\} = aF(k) + bG(k)\\)\nThis means the Fourier transform of a sum is the sum of the Fourier transforms, allowing us to analyze complex signals by breaking them into simpler components.\nShift Theorem: \\(\\mathcal{F}\\{f(x-a)\\} = e^{-ika}F(k)\\)\nA shift in the spatial domain corresponds to a phase change in the frequency domain, critical for understanding how optical elements that cause phase shifts affect the spectrum.\nConvolution Theorem: \\(\\mathcal{F}\\{f * g\\} = F(k) \\cdot G(k)\\)\nConvolution in the spatial domain becomes multiplication in the frequency domain. This is particularly useful in optics, where the effect of a lens or aperture can be modeled as a convolution operation.\nParseval’s Theorem: \\(\\int |f(x)|^2 dx = \\int |F(k)|^2 dk\\)\nThis theorem establishes energy conservation between domains, showing that the total energy in a signal is preserved in its Fourier transform.\n\n\n\n7.0.7 Common Fourier Transform Pairs\n\n\n\n\n\n\n\nFunction\nFourier Transform\n\n\n\n\n\\(\\delta(x)\\) (Delta function)\n\\(1\\) (constant)\n\n\n\\(1\\) (constant)\n\\(\\delta(k)\\) (Delta function)\n\n\n\\(\\text{rect}(x)\\) (Rectangle function)\n\\(\\text{sinc}(k)\\) (Sinc function)\n\n\n\\(e^{-\\pi x^2}\\) (Gaussian)\n\\(e^{-\\pi k^2}\\) (Gaussian)\n\n\n\\(\\cos(2\\pi ax)\\)\n\\(\\frac{1}{2}[\\delta(k-a) + \\delta(k+a)]\\)\n\n\n\nUnderstanding these transform pairs is essential for optical analysis. For example, a rectangular aperture produces a sinc-function diffraction pattern, and a Gaussian beam maintains its Gaussian profile under propagation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.0.7.1 Correspondence to Plane Wave Angular Components\nOne of the most profound insights in Fourier optics is the relationship between spatial frequencies and the angular spectrum of plane waves. To understand this relationship, consider a plane wave \\(U(x,y,z)\\) with wavevector \\(\\mathbf{k}\\) and wavelength \\(\\lambda\\) incident on the plane \\(z=0\\). The wavevector can be written as:\n\\[\\mathbf{k} = k_x\\hat{\\mathbf{x}} + k_y\\hat{\\mathbf{y}} + k_z\\hat{\\mathbf{z}}\\]\nwhere \\(|\\mathbf{k}| = 2\\pi/\\lambda\\). The components of this wavevector can be expressed in terms of the propagation angles \\(\\theta_x\\) and \\(\\theta_y\\) (with respect to the \\(z\\)-axis):\n\\[k_x = \\frac{2\\pi}{\\lambda}\\sin\\theta_x\\] \\[k_y = \\frac{2\\pi}{\\lambda}\\sin\\theta_y\\] \\[k_z = \\frac{2\\pi}{\\lambda}\\cos\\theta_z\\]\nwhere \\(\\cos\\theta_z = \\sqrt{1-\\sin^2\\theta_x-\\sin^2\\theta_y}\\) from the constraint that \\(|\\mathbf{k}| = 2\\pi/\\lambda\\).\n\n\n\n\n\n\nFigure 7.4— Principle of plane wave angular decomposition. (Image taken from Saleh/Teich “Principles of Photonics”)\n\n\n\nAt the plane \\(z=0\\), this plane wave can be represented as:\n\\[U(x,y,0) = U_0 e^{j(k_x x + k_y y)}\\]\nwhere \\(k_x/2\\pi\\) and \\(k_x/2\\pi\\) are the spatial frequencies of the plane wave along the x- and y direction. This equation shows that a plane wave propagating at angles \\(\\theta_x\\) and \\(\\theta_y\\) manifests as a spatial harmonic function at the \\(z=0\\) plane, with spatial frequencies directly related to the propagation angles:\n\\[\\frac{k_x}{2\\pi} = \\frac{1}{\\lambda}\\sin\\theta_x\\] \\[\\frac{k_y}{2\\pi} = \\frac{1}{\\lambda}\\sin\\theta_y\\]\nWe can match now the spatial frequencies of the object \\(f(x,y)\\) to the plane wave \\(U(x,y,0)\\) by adjusting the wavevector angles \\(\\theta_x, \\theta_y\\) to yield the same periodicity.\nThe means that\n\\[U(x,y,0)=f(x,y)\\]\nor concerning the frequencies\n\\[\\nu_x = \\frac{k_x}{2\\pi}=\\frac{1}{\\lambda}\\sin\\theta_x\\] \\[\\nu_y = \\frac{k_y}{2\\pi}=\\frac{1}{\\lambda}\\sin\\theta_y\\]\nThis means each spatial frequency of the sample \\(f(x,y)\\) is diffracting the incident plane wave \\(U(x,y,z)\\) into a certain angle, when the frequencies are matched. Behind the sample, the plane wave is propagating further without any change with the additional phase factor \\(e^{-i k_z z}\\) such that\n\\[U(x,y,z) = U(x,y,0) e^{-ik_z z} = U_0 e^{i(k_x x + k_y y)} e^{-ik_z z}\\]\nwhere the wavevector component \\(k_z\\) is given by:\n\\[k_z = \\sqrt{k^2 - k_x^2 - k_y^2} = \\frac{2\\pi}{\\lambda}\\sqrt{1 - \\lambda^2(\\nu_x^2 + \\nu_y^2)}\\]\nThis expression for \\(k_z\\) shows how the propagation along the z-direction depends on the spatial frequencies in the x and y directions. This relationship provides a direct connection between the spatial structure of an object and the directions in which light propagates after interacting with it.\n\n\n\n\n\n\nSpatial Frequency and Propagation Angles of a Grating\n\n\n\n\n\nWe saw this principle in action when analyzing diffraction gratings, where we decomposed the grating’s periodic structure into angular components using the grating vector. For a grating with period \\(d\\), the spatial frequency is \\(\\nu_x = 1/d\\), and the directions of diffracted orders are given by:\n\\[\\sin\\theta_m = m\\lambda/d = m\\lambda\\nu_x\\]\nwhere \\(m\\) is the diffraction order. This shows how the grating’s spatial frequency determines the angles of diffracted light, which is a specific application of the more general Fourier relationship between spatial frequencies and propagation angles.\n\n\n\n\n\n\n\n\nFigure 7.5— Visualization of a 2D object containing a single spatial frequency in the x-direction. (a) The object pattern showing sinusoidal variation along x with frequency νₓ. (b) The Fourier transform magnitude of the object, showing two symmetric points corresponding to ±νₓ. (c) The corresponding angular spectrum representation, where the spatial frequency νₓ maps to specific diffraction angles ±θ according to sin(θ) = λνₓ.",
    "crumbs": [
      " Lecture 5",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html",
    "href": "lectures/lecture06/01-lecture06.html",
    "title": "8  Spatial Spectral Analysis",
    "section": "",
    "text": "8.0.1 Transfer Function of Free space\nCorresponding to our previous analysis, the angular spectrum representation can be formalized using Fourier analysis. The complex amplitude transmittance \\(f(x,y)\\) can be written as a Fourier transform\n\\[f(x,y)=\\iint_{-\\infty}^{\\infty} F(\\nu_x,\\nu_y) e^{i 2\\pi(\\nu_x x + \\nu_y y)}d\\nu_x d\\nu_y\\]\nwhere \\(F(\\nu_x,\\nu_y)\\) give the amplitudes of the frequency components of the transmittance. With our previous expression, then the field at any plane \\(z\\) can be obtained by:\n\\[U(x,y,z) = \\iint_{-\\infty}^{\\infty} F(\\nu_x,\\nu_y) e^{i 2\\pi(\\nu_x x + \\nu_y y)} e^{-i k_z z} d\\nu_x d\\nu_y\\]\nwhere \\(k_z = 2\\pi\\sqrt{(1/\\lambda)^2 - \\nu_x^2 - \\nu_y^2}\\) is the z-component of the wavevector.\nThis formulation shows that the field at any distance \\(z\\) can be calculated by multiplying each spatial frequency component by the appropriate phase factor \\(e^{-i k_z z}\\) and then performing an inverse Fourier transform. This approach provides an elegant and computationally efficient method for modeling wave propagation, particularly in homogeneous media.\nFor propagating waves, where \\(\\nu_x^2 + \\nu_y^2 &lt; (1/\\lambda)^2\\), the factor \\(e^{-i k_z z}\\) represents a phase shift. For evanescent waves, where \\(\\nu_x^2 + \\nu_y^2 &gt; (1/\\lambda)^2\\), \\(k_z\\) becomes imaginary, resulting in exponential decay with distance.\nWe now examine the propagation of a monochromatic optical wave of wavelength \\(\\lambda\\) and complex amplitude \\(U(x, y, z)\\) in the free space between the planes \\(z=0\\) and \\(z=d\\), called the input and output planes, respectively. Given the complex amplitude of the wave at the input plane, \\(f(x, y)=U(x, y, 0)\\), we want to determine the complex amplitude at the output plane, \\(g(x, y)=U(x, y, d)\\).\nThe input field \\(f(x,y)\\) propagates through free space to form the output field \\(g(x,y)\\). Using the angular spectrum representation, we can express the relationship between input and output as:\n\\[g(x,y) = \\iint_{-\\infty}^{\\infty} F(\\nu_x,\\nu_y) e^{i 2\\pi(\\nu_x x + \\nu_y y)} e^{-i k_z d} d\\nu_x d\\nu_y\\]\nwhere \\(F(\\nu_x,\\nu_y)\\) is the Fourier transform of \\(f(x,y)\\), and \\(k_z = 2\\pi\\sqrt{(1/\\lambda)^2 - \\nu_x^2 - \\nu_y^2}\\) is the z-component of the wavevector.\nThe transfer function of free space, denoted as \\(H(\\nu_x,\\nu_y)\\), is defined as the ratio of the output spectrum to the input spectrum:\n\\[H(\\nu_x,\\nu_y) = e^{-i k_z d} = e^{-i 2\\pi d\\sqrt{(1/\\lambda)^2 - \\nu_x^2 - \\nu_y^2}}\\]\nThis transfer function has two distinct regimes based on the values of \\(\\nu_x\\) and \\(\\nu_y\\):\nA simplification of the transfer function of free space maybe obtained when considering only spatial frequencies that are much smaller than the cut-off frequency. This simplificaltion is called the Fresnel approximation and leads to\n\\[\nH\\left(\\nu_x, \\nu_y\\right) \\approx H_0 \\exp \\left[i \\pi \\lambda d\\left(\\nu_x^2+\\nu_y^2\\right)\\right]\n\\]\nIts inverse Fourier transform is the impulse response function \\(h(x,y)\\), which is given by\n\\[\nh(x, y) \\approx h_0 \\exp \\left[-i k \\frac{x^2+y^2}{2 d}\\right]\n\\]\nwith \\(h_0=(i / \\lambda d) \\exp (-i k d)\\).\nFigure 8.2— The magnitude of the free-space transfer function. For propagating waves (\\(\\nu_x^2 + \\nu_y^2 &lt; 1/\\lambda^2\\)), the transfer function has magnitude 1, representing pure phase delay. For evanescent waves (\\(\\nu_x^2 + \\nu_y^2 &gt; 1/\\lambda^2\\)), the magnitude decays exponentially with distance from the origin.\nFigure 8.3— The phase of the free-space transfer function. For propagating waves (ν_x² + ν_y² &lt; 1/λ²), the transfer function introduces a phase delay that increases with spatial frequency. This phase represents the wavefront curvature during propagation.\nThe figure below now visualizes the effect of free space propagation on the phase of the transfer function when light of certain wavelength is used to illuminate and rectangular aperture of 10 µm width.\nFigure 8.4— Effect of spatial frequency cutoff on image reconstruction. (a) Original rectangular aperture. (b-d) Reconstructed intensity after applying different wavelength cutoffs. As the cutoff wavelength increases, more high-frequency components are lost, resulting in blurring and loss of edge sharpness.\nThis description of free space propagation provides insight into important phenomena such as:\nDiffraction limits: Spatial frequencies beyond \\(1/\\lambda\\) correspond to evanescent waves that decay exponentially with distance, explaining why sub-wavelength features cannot be observed in the far field. This would mean that light should not propagate through subwavelength holes. This is what you would expect for the grid in front of your microwave. Yet, light can penetrate through subwavelength holes not only as evanescent fields. Bethe used in 1944 an idealized model where the film was infinitely thin and the metal was a perfect conductor. Under these assumptions, he derived a straightforward expression for the transmission efficiency \\(\\eta_B\\) (normalized to the aperture area):\n\\[\\eta_B = \\frac{64(kr)^4}{27\\pi^2}\\]\nwhere \\(k = 2\\pi/\\lambda\\) represents the wavevector magnitude of the incoming light with wavelength \\(\\lambda\\), and \\(r\\) is the hole radius. This equation clearly shows that \\(\\eta_B\\) scales as \\((r/\\lambda)^4\\), indicating that the optical transmission would decrease rapidly as \\(\\lambda\\) becomes larger than \\(r\\).\nHowever, real apertures with finite depth exhibit waveguide properties. Light transmission through these waveguides differs fundamentally from free-space propagation. The confined geometry modifies the field’s dispersion relation, with the aperture’s lateral dimensions determining the cutoff wavelength \\(\\lambda_c\\) beyond which propagation ceases. When incident wavelength \\(\\lambda &gt; \\lambda_c\\), transmission decays exponentially, indicating the non-propagating regime (Fig. 2). In real metals, the transition from propagative to evanescent regimes occurs gradually rather than at a sharply defined \\(\\lambda_c\\).\nThe transmission of light through subwavelength apertures provides exciting new tools for spectroscopy and imaging applications. These tools enable the manipulation of light at the nanoscale, leading to advancements in areas such as microscopy, sensing, and communication.\nResolution limits: An optical system with a maximum acceptance angle \\(\\theta_{max}\\) can only capture spatial frequencies up to \\(\\sin\\theta_{max}/\\lambda\\), limiting the finest details that can be resolved.\nSpatial filtering: Optical components like apertures and lenses act as spatial filters, selectively transmitting or modifying certain spatial frequency components.",
    "crumbs": [
      " Lecture 6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html#amplitude-modulation",
    "href": "lectures/lecture06/01-lecture06.html#amplitude-modulation",
    "title": "8  Spatial Spectral Analysis",
    "section": "8.1 Amplitude Modulation",
    "text": "8.1 Amplitude Modulation\nLet’s examine how spatial amplitude modulation affects the angular propagation of light. Consider a transparency with complex amplitude transmittance \\(f_0(x, y)\\). If its Fourier transform \\(F_0(\\nu_x, \\nu_y)\\) extends over spatial frequency ranges \\(\\pm \\Delta \\nu_x\\) and \\(\\pm \\Delta \\nu_y\\) in the \\(x\\) and \\(y\\) directions, the transparency will deflect an incident plane wave by angles \\(\\theta_x\\) and \\(\\theta_y\\) within the ranges:\n\\[\\pm \\sin^{-1}(\\lambda \\Delta \\nu_x)\\]\nand\n\\[\\pm \\sin^{-1}(\\lambda \\Delta \\nu_y)\\]\nrespectively.\nNow consider a second transparency with complex amplitude transmittance:\n\\[f(x, y) = f_0(x, y) e^{-i 2\\pi(\\nu_{x0}x + \\nu_{y0}y)}\\]\nwhere \\(f_0(x, y)\\) varies slowly compared to the exponential carrier term, meaning \\(\\Delta \\nu_x \\ll \\nu_{x0}\\) and \\(\\Delta \\nu_y \\ll \\nu_{y0}\\). This represents an amplitude-modulated function with spatial carrier frequencies \\(\\nu_{x0}\\) and \\(\\nu_{y0}\\) and modulation function \\(f_0(x, y)\\). According to the shift property of the Fourier transform, the transform of \\(f(x, y)\\) is:\n\\[F_0(\\nu_x - \\nu_{x0}, \\nu_y - \\nu_{y0})\\]\nThe transparency will deflect a plane wave in directions centered around the angles:\n\\[\\theta_{x0} = \\sin^{-1}(\\lambda\\nu_{x0})\\]\nand\n\\[\\theta_{y0} = \\sin^{-1}(\\lambda\\nu_{y0})\\]\nThis behavior can be understood by viewing \\(f(x, y)\\) as a combination of the base transmittance \\(f_0(x, y)\\) with a phase grating having transmittance \\(e^{-i 2\\pi(\\nu_{x0}x + \\nu_{y0}y)}\\) that provides the angular deflection.\n\n\n\n\n\n\n\n\nFigure 8.7— Visualization of amplitude modulation and the corresponding angular deflection. (a) The base pattern f₀(x,y) - a Gaussian envelope. (b) A carrier wave with spatial frequency ν₀. (c) The amplitude-modulated pattern f(x,y)=f₀(x,y)e^(-j2πν₀x). (d) Fourier transforms showing how the spectrum shifts with modulation, corresponding to angular deflection.\n\n\n\n\n\nThis principle enables spatial-frequency multiplexing, where two images \\(f_1(x, y)\\) and \\(f_2(x, y)\\) can be recorded on the same transparency using the encoding:\n\\[f(x, y) = f_1(x, y)e^{-i 2\\pi(\\nu_{x1}x + \\nu_{y1}y)} + f_2(x, y)e^{-i 2\\pi(\\nu_{x2}x + \\nu_{y2}y)}\\]\nBy illuminating this combined transparency with a plane wave, the two images are deflected at different angles determined by their carrier frequencies, allowing them to be spatially separated. This technique is particularly valuable in holography, where separating different image components recorded on the same medium is often necessary.\n\n\n\n\n\n\nStructured Illumination Microscopy (SIM)\n\n\n\nThe amplitude modulation concepts presented here form the theoretical foundation for Structured Illumination Microscopy (SIM), a super-resolution imaging technique. In SIM, a sample is illuminated with a known spatially structured pattern, typically a sinusoidal grid. This can be mathematically represented as an illumination intensity pattern:\n\\[I_{\\text{illum}}(x,y) = I_0[1 + m\\cos(2\\pi\\nu_0 x + \\phi)]\\]\nwhere \\(I_0\\) is the average intensity, \\(m\\) is the modulation depth, \\(\\nu_0\\) is the spatial frequency of the illumination pattern, and \\(\\phi\\) is the phase.\nWhen this structured pattern illuminates a sample with spatial structure \\(S(x,y)\\), the resulting observed image is simply the product:\n\\[D(x,y) = S(x,y) \\cdot I_{\\text{illum}}(x,y)\\]\nSubstituting the illumination pattern:\n\\[D(x,y) = S(x,y) \\cdot I_0[1 + m\\cos(2\\pi\\nu_0 x + \\phi)]\\] \\[D(x,y) = I_0 \\cdot S(x,y) + I_0 \\cdot m \\cdot S(x,y)\\cos(2\\pi\\nu_0 x + \\phi)\\]\nUsing Euler’s formula, we can rewrite the cosine term:\n\\[D(x,y) = I_0 \\cdot S(x,y) + \\frac{I_0 \\cdot m}{2} \\cdot S(x,y)[e^{j(2\\pi\\nu_0 x + \\phi)} + e^{-j(2\\pi\\nu_0 x + \\phi)}]\\]\nIn the frequency domain, this becomes:\n\\[\\tilde{D}(\\nu_x,\\nu_y) = I_0\\tilde{S}(\\nu_x,\\nu_y) + \\frac{I_0 \\cdot m}{2}[\\tilde{S}(\\nu_x-\\nu_0,\\nu_y)e^{j\\phi} + \\tilde{S}(\\nu_x+\\nu_0,\\nu_y)e^{-j\\phi}]\\]\nwhere \\(\\tilde{S}\\) is the Fourier transform of the sample structure, and \\(\\tilde{D}\\) is the Fourier transform of the detected image.\nThis equation reveals how structured illumination enables access to high spatial frequencies beyond the conventional diffraction limit. In standard microscopy, the optical system acts as a low-pass filter due to the diffraction limit, restricting detectable spatial frequencies to \\(|\\nu| \\leq \\nu_{\\text{max}} = \\frac{NA}{\\lambda}\\), where NA is the numerical aperture and λ is the wavelength.\nThe key insight is that structured illumination creates a “moiré effect” between the illumination pattern and the sample structure. Consider a sample with high spatial frequency components that exceed \\(\\nu_{\\text{max}}\\) and would normally be undetectable. When this sample is illuminated with the structured pattern of frequency \\(\\nu_0\\), these high-frequency components interact with the illumination pattern to produce difference frequencies that fall within the detectable range.\n\n\n\n\n\n\nFigure 8.8— The moiré effect in SIM. When a sample with high spatial frequency features is illuminated with a structured pattern, the interference creates moiré fringes at lower frequencies that can be detected by the microscope. This allows information about sub-diffraction structures to be encoded in observable signals. (see Gustafsson, M. G. L. Nonlinear structured-illumination microscopy: Wide-field fluorescence imaging with theoretically unlimited resolution. Proc. Natl. Acad. Sci. 102, 13081–13086 (2005))\n\n\n\nSpecifically, sample features with spatial frequency \\(\\nu_s &gt; \\nu_{\\text{max}}\\) combine with the illumination frequency \\(\\nu_0\\) to produce components at \\(\\nu_s - \\nu_0\\) and \\(\\nu_s + \\nu_0\\). If \\(\\nu_s - \\nu_0 &lt; \\nu_{\\text{max}}\\), then this difference frequency becomes detectable by the optical system, effectively bringing previously inaccessible high-frequency information into the observable range.\nFor example, if a sample contains structures with spatial frequency \\(\\nu_s = 1.7\\nu_{\\text{max}}\\) and we apply illumination with \\(\\nu_0 = 0.8\\nu_{\\text{max}}\\), the difference frequency becomes \\(\\nu_s - \\nu_0 = 0.9\\nu_{\\text{max}}\\), which falls within the detectable range. This allows us to extract information about sample features that would be invisible under conventional illumination.\nTo separate and reconstruct these frequency-shifted components, we need multiple images with different phases of the illumination pattern. Typically, three images with phases \\(\\phi = 0°, 120°, 240°\\) are acquired, allowing us to solve the following system of equations:\n\\[\\begin{pmatrix} D_1 \\\\ D_2 \\\\ D_3 \\end{pmatrix} = \\begin{pmatrix} 1 & e^{j\\phi_1} & e^{-j\\phi_1} \\\\ 1 & e^{j\\phi_2} & e^{-j\\phi_2} \\\\ 1 & e^{j\\phi_3} & e^{-j\\phi_3} \\end{pmatrix} \\begin{pmatrix} I_0\\tilde{S}(\\nu) \\\\ \\frac{I_0 \\cdot m}{2}\\tilde{S}(\\nu-\\nu_0) \\\\ \\frac{I_0 \\cdot m}{2}\\tilde{S}(\\nu+\\nu_0) \\end{pmatrix}\\]\nBy extracting these frequency-shifted components and computationally restoring them to their original positions in frequency space, we can reconstruct spatial frequencies beyond the conventional diffraction limit, typically achieving a resolution improvement factor of 2 in each dimension, or a factor of 2 beyond what would be possible with the same wavelength and numerical aperture in conventional microscopy.",
    "crumbs": [
      " Lecture 6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html#frequency-modulation",
    "href": "lectures/lecture06/01-lecture06.html#frequency-modulation",
    "title": "8  Spatial Spectral Analysis",
    "section": "8.2 Frequency Modulation",
    "text": "8.2 Frequency Modulation\nWe now examine the transmission of a plane wave through a transparency made of a “collage” of several regions, the transmittance of each of which is a harmonic function of some spatial frequency, as illustrated below. If the dimensions of each region are much greater than the period, each region acts as a grating or a prism that deflects the wave in some direction, so that different portions of the incident wavefront are deflected into different directions. This principle may be used to create maps of optical interconnections, which may be used in optical computing applications\n\n\n\n\n\n\nFigure 8.9— Deflection of light by a transparency made of several harmonic functions (phase gratings) of different spatial frequencies. (source Saleh/Teich Principles of Photonics).\n\n\n\nThis concept of directed light deflection through controlled spatial frequency modulation stands in stark contrast to what happens when spatial frequencies are distributed randomly, as we’ll see next with speckle patterns.",
    "crumbs": [
      " Lecture 6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html#speckle-random-frequency-modulation",
    "href": "lectures/lecture06/01-lecture06.html#speckle-random-frequency-modulation",
    "title": "8  Spatial Spectral Analysis",
    "section": "8.3 Speckle: Random Frequency Modulation",
    "text": "8.3 Speckle: Random Frequency Modulation\nWhen coherent light interacts with a rough surface or passes through a scattering medium, the resulting intensity pattern exhibits a characteristic granular appearance known as speckle. This phenomenon represents a natural example of random spatial frequency modulation that can be elegantly described using the Fourier optics framework we’ve developed.\nWhile the optical interconnect example above demonstrates how carefully designed spatial frequency distributions can create predictable, useful light paths, speckle represents the opposite case - where randomly distributed spatial frequencies create complex interference patterns. In essence, speckle is what happens when nature creates its own “random optical interconnect map.”\n\n8.3.1 Speckle Formation\nSpeckle arises when coherent wavefronts undergo spatially varying phase shifts that cause complex interference. From our spatial frequency perspective, we can model a rough surface as applying a random phase modulation to the incident wavefront:\n\\[E_{\\text{scattered}}(x,y) = E_0 e^{i\\phi(x,y)}\\]\nwhere \\(\\phi(x,y)\\) is a random phase function corresponding to the surface height variations. When this scattered field propagates and interferes with itself, it produces the characteristic speckle pattern. Unlike our controlled interconnect example, where each region deliberately directs light in a specific direction, here each microscopic region of the rough surface randomly deflects light, creating a complex superposition of wavefronts with random phases and directions.\n\n\n\n\n\n\n\n\nFigure 8.10— Speckle formation process. (a) Coherent light incident on a rough surface acquires random phase shifts. (b) The resulting scattered field creates a speckle pattern in the observation plane. (c) The characteristic granular appearance of a fully developed speckle pattern.\n\n\n\n\n\nThe random yet deterministic nature of speckle patterns shares remarkable similarities with the weight matrices of trained neural networks, offering an intriguing conceptual framework that connects Fourier optics with modern computational systems.\n\n\n\n\n\n\nConceptual Connections to Neuronal Networks\n\n\n\n\n\n\nWave Superposition vs. Neuronal Contributions: Just as each speckle grain represents the constructive interference of many wave components, each connection in a neural network can be viewed as the “superposition” of many training examples that collectively shaped that weight.\nInformation Encoding:\n\nSpeckle patterns encode information about the scattering medium in a distributed, holographic manner\nNeural networks encode learned features in a distributed pattern across weight matrices\n\nStatistical Properties:\n\nSpeckle intensity follows a negative exponential distribution for fully developed speckle\nNeural network weights often approximate Gaussian distributions after training\n\nFourier Domain Representation:\n\nSpeckle can be analyzed in the Fourier domain to reveal the spatial frequency content of the scattering medium\nNeural network weights can be analyzed in the frequency domain to reveal the spectrum of features they’ve learned to detect\n\n\nThe mathematical connection becomes even more apparent when considering both systems as complex-valued functions:\n\nA speckle field at a plane can be expressed as: \\(E(x,y) = \\sum_k A_k e^{j\\phi_k} e^{j(k_x x + k_y y)}\\)\nA neural network layer output can be expressed as: \\(y_i = \\sigma\\left(\\sum_j w_{ij} x_j + b_i\\right)\\)\n\nBoth involve a weighted sum of inputs, and both transform information from one domain to another through operations that can be represented as spatial filtering operations.\nThese connections between speckle field and information processing give rise to research field of imaging and computing with disordered materials.\n\n\n\n\n\n\nFigure 8.11— DiffuserCam: A compressive framework allows 3D imaging using a surface diffuser and a camera, using prior calibration of the diffuser and a minimization algorithm. Image taken from the perspective article Gigan, S. Imaging and computing with disorder. Nat. Phys. 18, 980–985 (2022).",
    "crumbs": [
      " Lecture 6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html#frequency-modulation-with-continuously-varying-spatial-frequencies",
    "href": "lectures/lecture06/01-lecture06.html#frequency-modulation-with-continuously-varying-spatial-frequencies",
    "title": "8  Spatial Spectral Analysis",
    "section": "8.4 Frequency Modulation with Continuously Varying Spatial Frequencies",
    "text": "8.4 Frequency Modulation with Continuously Varying Spatial Frequencies\nA transparency may also have a harmonic transmittance with a spatial frequency that varies gradually across its surface, similar to how a musical note changes pitch in an FM radio signal. This is easier to visualize than the fixed-frequency patterns we discussed earlier.\nLet’s look at a transparency with this phase-altering property:\n\\[f(x, y) = \\exp[-i2\\pi\\phi(x, y)]\\]\nwhere \\(\\phi(x, y)\\) is a smooth function that changes slowly compared to the wavelength of light (\\(\\lambda\\)).\nIf we zoom in around any point \\((x_0, y_0)\\), we can approximate \\(\\phi(x, y)\\) using the first few terms of a Taylor series (which you’ve seen in calculus):\n\\[\\phi(x, y) \\approx \\phi(x_0, y_0) + (x-x_0)\\nu_x + (y-y_0)\\nu_y\\]\nwhere \\(\\nu_x\\) and \\(\\nu_y\\) are just the partial derivatives of \\(\\phi\\) with respect to \\(x\\) and \\(y\\) at that point:\n\\[\\nu_x = \\frac{\\partial\\phi}{\\partial x} \\quad \\text{and} \\quad \\nu_y = \\frac{\\partial\\phi}{\\partial y}\\]\nNear this point, our transparency function behaves like:\n\\[\\exp[-i2\\pi(\\nu_x x + \\nu_y y)]\\]\nwhich we recognize as a harmonic function with local spatial frequencies \\(\\nu_x\\) and \\(\\nu_y\\).\nSince these derivatives change as we move across the transparency, the spatial frequencies also vary with position. As a result, different parts of the incoming light wave get deflected by different angles:\n\\[\\theta_x = \\sin^{-1}\\left(\\lambda\\frac{\\partial\\phi}{\\partial x}\\right) \\quad \\text{and} \\quad \\theta_y = \\sin^{-1}\\left(\\lambda\\frac{\\partial\\phi}{\\partial y}\\right)\\]\nThis is how optical elements like lenses can bend light in position-dependent ways to focus or shape wavefronts.\n\n8.4.1 Imaging\nWhen a thin transparency has a complex amplitude transmittance of\n\\[f(x, y)=\\exp \\left(j \\pi x^2 / \\lambda f\\right)\\],\nit introduces a phase shift of \\(2 \\pi \\phi(x, y)\\) where \\(\\phi(x, y)= -x^2 / 2 \\lambda f\\).\n\n\n\n\n\n\n\n\nFigure 8.12— Phase function of a cylindrical Fourier lens. (left) The 2D phase profile showing how phase varies quadratically with x. (right) The resulting deflection angle as a function of position, showing the linear relationship that causes focusing.\n\n\n\n\n\nThis phase profile causes the wave at position \\((x, y)\\) to be deflected by angles \\(\\theta_x= \\sin^{-1}(\\lambda \\partial \\phi / \\partial x)=\\sin^{-1}(-x / f)\\) and \\(\\theta_y=0\\). For small values where \\(|x / f| \\ll 1\\), the deflection angle simplifies to \\(\\theta_x \\approx-x / f\\), creating a linear relationship between deflection angle and position. When a plane wave illuminates this transparency, each point of the wavefront experiences a position-dependent deflection, transforming the overall wavefront shape. At each position \\(x\\), the local wavevector is redirected by an angle \\(-x / f\\), causing all light rays to converge at a focal point located at distance \\(f\\) from the transparency along the optical axis, as illustrated below.\n\n\n\n\n\n\nFigure 8.13— A transparency with transmittance \\(f(x, y)=\\exp \\left(j \\pi x^2 / \\lambda f\\right)\\) bends the wave at position \\(x\\) by an angle \\(\\theta_x \\approx-x / f\\), functioning as a cylindrical lens with focal length \\(f\\).\n\n\n\nThis transparency operates exactly like a cylindrical lens with focal length \\(f\\). Extending this concept, a transparency with transmittance \\(f(x, y)=\\exp \\left[j \\pi\\left(x^2+y^2\\right) / \\lambda f\\right]\\) acts as a spherical lens with focal length \\(f\\). This elegant mathematical expression perfectly captures the phase transformation property of a thin lens.",
    "crumbs": [
      " Lecture 6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>| echo: false</span>"
    ]
  }
]